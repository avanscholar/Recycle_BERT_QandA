{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "885845d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b9e30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some basic libraries\n",
    "import numpy as pd\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fd5e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (5900, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.resconrec.2022.106639</td>\n",
       "      <td>Efficient chemical recycling of waste polyethy...</td>\n",
       "      <td>We present an efficient chemical recycling/dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.conbuildmat.2022.127084</td>\n",
       "      <td>Recycled Non-Biodegradable polyethylene tereph...</td>\n",
       "      <td>In this study, the use of recycled non-biodegr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.wasman.2021.09.009</td>\n",
       "      <td>Hydrolysis of waste polyethylene terephthalate...</td>\n",
       "      <td>Hydrolysis of polyethylene terephthalate (PET)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.jclepro.2022.134083</td>\n",
       "      <td>Polyethylene terephthalate (PET) waste plastic...</td>\n",
       "      <td>This work investigates the recycling potential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.crgsc.2022.100280</td>\n",
       "      <td>Development of composite material from Recycle...</td>\n",
       "      <td>Since 1980, numerous studies have been conduct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "0    10.1016/j.resconrec.2022.106639   \n",
       "1  10.1016/j.conbuildmat.2022.127084   \n",
       "2       10.1016/j.wasman.2021.09.009   \n",
       "3      10.1016/j.jclepro.2022.134083   \n",
       "4        10.1016/j.crgsc.2022.100280   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Efficient chemical recycling of waste polyethy...   \n",
       "1  Recycled Non-Biodegradable polyethylene tereph...   \n",
       "2  Hydrolysis of waste polyethylene terephthalate...   \n",
       "3  Polyethylene terephthalate (PET) waste plastic...   \n",
       "4  Development of composite material from Recycle...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  We present an efficient chemical recycling/dep...  \n",
       "1  In this study, the use of recycled non-biodegr...  \n",
       "2  Hydrolysis of polyethylene terephthalate (PET)...  \n",
       "3  This work investigates the recycling potential...  \n",
       "4  Since 1980, numerous studies have been conduct...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load of pet\n",
    "df_pet = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/2_abstract_pet_recycle_methods.csv')\n",
    "df_pet =  df_pet.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pet.shape)\n",
    "df_pet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9f862bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (5900, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.jece.2022.108332</td>\n",
       "      <td>Morpho-structural and thermo-mechanical charac...</td>\n",
       "      <td>In this work, a complete sorting and character...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.polymdegradstab.2022.109981</td>\n",
       "      <td>Chemical recycling of waste polystyrene by the...</td>\n",
       "      <td>Chemical recycling by thermo-catalytic pyrolys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.fuel.2021.121835</td>\n",
       "      <td>A methodology for recycling waste expanded pol...</td>\n",
       "      <td>While polystyrene polymers see broad usage in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.egyr.2022.01.071</td>\n",
       "      <td>Circular economy of expanded polystyrene conta...</td>\n",
       "      <td>Plastic industry is ubiquitous worldwide, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.clema.2022.100095</td>\n",
       "      <td>Recycling of waste expanded polystyrene concre...</td>\n",
       "      <td>The recycling of waste expanded polystyrene (E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     DOI  \\\n",
       "0             10.1016/j.jece.2022.108332   \n",
       "1  10.1016/j.polymdegradstab.2022.109981   \n",
       "2             10.1016/j.fuel.2021.121835   \n",
       "3             10.1016/j.egyr.2022.01.071   \n",
       "4            10.1016/j.clema.2022.100095   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Morpho-structural and thermo-mechanical charac...   \n",
       "1  Chemical recycling of waste polystyrene by the...   \n",
       "2  A methodology for recycling waste expanded pol...   \n",
       "3  Circular economy of expanded polystyrene conta...   \n",
       "4  Recycling of waste expanded polystyrene concre...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  In this work, a complete sorting and character...  \n",
       "1  Chemical recycling by thermo-catalytic pyrolys...  \n",
       "2  While polystyrene polymers see broad usage in ...  \n",
       "3  Plastic industry is ubiquitous worldwide, and ...  \n",
       "4  The recycling of waste expanded polystyrene (E...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load of ps\n",
    "df_ps = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/0_abstract_ps_recycle_methods.csv')\n",
    "df_ps =  df_ps.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_ps.shape)\n",
    "df_ps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ec7d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (5900, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DOI Title Abstract\n",
       "0   1     2        0\n",
       "1   1     2        0\n",
       "2   1     2        0\n",
       "3   1     2        0\n",
       "4   1     2        0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load of pe\n",
    "df_pe = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/2_abstract_pe_recycle_methods.csv')\n",
    "df_pe =  df_pe.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pe.shape)\n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecbba088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (5900, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.conbuildmat.2022.128977</td>\n",
       "      <td>Rheological behavior and mechanical properties...</td>\n",
       "      <td>The development of wood-plastic composites (WP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.jece.2022.108332</td>\n",
       "      <td>Morpho-structural and thermo-mechanical charac...</td>\n",
       "      <td>In this work, a complete sorting and character...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.polymer.2022.125006</td>\n",
       "      <td>Layer-by-layer stacking, low-temperature weldi...</td>\n",
       "      <td>High-value recycling and reuse of plastic prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.wasman.2020.08.050</td>\n",
       "      <td>Development of thermoplastic composites based ...</td>\n",
       "      <td>In the last several years, the electronic wast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.matlet.2022.132942</td>\n",
       "      <td>Short basalt fibre reinforced recycled polypro...</td>\n",
       "      <td>Additive Manufacturing (3D Printing, and speci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "0  10.1016/j.conbuildmat.2022.128977   \n",
       "1         10.1016/j.jece.2022.108332   \n",
       "2      10.1016/j.polymer.2022.125006   \n",
       "3       10.1016/j.wasman.2020.08.050   \n",
       "4       10.1016/j.matlet.2022.132942   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Rheological behavior and mechanical properties...   \n",
       "1  Morpho-structural and thermo-mechanical charac...   \n",
       "2  Layer-by-layer stacking, low-temperature weldi...   \n",
       "3  Development of thermoplastic composites based ...   \n",
       "4  Short basalt fibre reinforced recycled polypro...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  The development of wood-plastic composites (WP...  \n",
       "1  In this work, a complete sorting and character...  \n",
       "2  High-value recycling and reuse of plastic prod...  \n",
       "3  In the last several years, the electronic wast...  \n",
       "4  Additive Manufacturing (3D Printing, and speci...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load of pp\n",
    "df_pp = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/2_abstract_pp_recycle_methods.csv')\n",
    "df_pp =  df_pp.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pp.shape)\n",
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7d525ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net shape of data frame: (23600, 3)\n"
     ]
    }
   ],
   "source": [
    "# concatenating df1 and df2 along rows\n",
    "df_net = pd.concat([df_pe, df_pet,df_pp, df_ps], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "107f3f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame before: (23045, 3)\n",
      "Shape of data frame after: (21081, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1533/9781845697662.2.102</td>\n",
       "      <td>5 Pyrolysis for recycling waste composites</td>\n",
       "      <td>\\n               Pyrolysis is a suitable proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.fuel.2021.120505</td>\n",
       "      <td>Low-pressure hydrothermal processing of mixed ...</td>\n",
       "      <td>The amount of polyolefin waste, which is 63% o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.conbuildmat.2022.127949</td>\n",
       "      <td>Cement mortars with ceramic molds shells and p...</td>\n",
       "      <td>Foundry industry produces millions of tons of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.arabjc.2022.104262</td>\n",
       "      <td>Degradation-fragmentation of marine plastic wa...</td>\n",
       "      <td>This review critically evaluates the plastic a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.conbuildmat.2019.117253</td>\n",
       "      <td>Performance of AC mixtures containing flakes o...</td>\n",
       "      <td>This paper evaluates the performance of asphal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "0        10.1533/9781845697662.2.102   \n",
       "1         10.1016/j.fuel.2021.120505   \n",
       "2  10.1016/j.conbuildmat.2022.127949   \n",
       "3       10.1016/j.arabjc.2022.104262   \n",
       "4  10.1016/j.conbuildmat.2019.117253   \n",
       "\n",
       "                                               Title  \\\n",
       "0        5 Pyrolysis for recycling waste composites    \n",
       "1  Low-pressure hydrothermal processing of mixed ...   \n",
       "2  Cement mortars with ceramic molds shells and p...   \n",
       "3  Degradation-fragmentation of marine plastic wa...   \n",
       "4  Performance of AC mixtures containing flakes o...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  \\n               Pyrolysis is a suitable proce...  \n",
       "1  The amount of polyolefin waste, which is 63% o...  \n",
       "2  Foundry industry produces millions of tons of ...  \n",
       "3  This review critically evaluates the plastic a...  \n",
       "4  This paper evaluates the performance of asphal...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the all entries with nan in abstract column\n",
    "NO_INDEX = []\n",
    "for i in range(len(df_net)):\n",
    "    if type(df_net.Abstract[i]) != float: \n",
    "        NO_INDEX.append(i)\n",
    "#Select some entries        \n",
    "df_net = df_net.iloc[NO_INDEX].reset_index(drop = True)\n",
    "print('Shape of data frame before:', df_net.shape)\n",
    "\n",
    "#Delete the all entries with integer in abstract column\n",
    "NO_INDEXX = []\n",
    "for i in range(len(df_net)):\n",
    "    if df_net.Abstract[i] != '0': \n",
    "        NO_INDEXX.append(i)\n",
    "#Select some entries        \n",
    "df_net = df_net.iloc[NO_INDEXX].reset_index(drop = True)\n",
    "print('Shape of data frame after:', df_net.shape)\n",
    "\n",
    "df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7559a65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1533/9781845697662.2.102</td>\n",
       "      <td>5 Pyrolysis for recycling waste composites</td>\n",
       "      <td>\\n               Pyrolysis is a suitable proce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.fuel.2021.120505</td>\n",
       "      <td>Low-pressure hydrothermal processing of mixed ...</td>\n",
       "      <td>The amount of polyolefin waste, which is 63% o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.conbuildmat.2022.127949</td>\n",
       "      <td>Cement mortars with ceramic molds shells and p...</td>\n",
       "      <td>Foundry industry produces millions of tons of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.arabjc.2022.104262</td>\n",
       "      <td>Degradation-fragmentation of marine plastic wa...</td>\n",
       "      <td>This review critically evaluates the plastic a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.conbuildmat.2019.117253</td>\n",
       "      <td>Performance of AC mixtures containing flakes o...</td>\n",
       "      <td>This paper evaluates the performance of asphal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "0        10.1533/9781845697662.2.102   \n",
       "1         10.1016/j.fuel.2021.120505   \n",
       "2  10.1016/j.conbuildmat.2022.127949   \n",
       "3       10.1016/j.arabjc.2022.104262   \n",
       "4  10.1016/j.conbuildmat.2019.117253   \n",
       "\n",
       "                                               Title  \\\n",
       "0        5 Pyrolysis for recycling waste composites    \n",
       "1  Low-pressure hydrothermal processing of mixed ...   \n",
       "2  Cement mortars with ceramic molds shells and p...   \n",
       "3  Degradation-fragmentation of marine plastic wa...   \n",
       "4  Performance of AC mixtures containing flakes o...   \n",
       "\n",
       "                                            Abstract  labels  \n",
       "0  \\n               Pyrolysis is a suitable proce...       0  \n",
       "1  The amount of polyolefin waste, which is 63% o...       0  \n",
       "2  Foundry industry produces millions of tons of ...       0  \n",
       "3  This review critically evaluates the plastic a...       0  \n",
       "4  This paper evaluates the performance of asphal...       0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_net['labels'] = 0   #relevent abstract\n",
    "df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eee52140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (5900, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.jcou.2022.101914</td>\n",
       "      <td>Hydrogen and alcohols production by Serratia s...</td>\n",
       "      <td>Climate change and its consequences have stimu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.cattod.2022.05.021</td>\n",
       "      <td>High-efficient production of fatty alcohol via...</td>\n",
       "      <td>Cu/SBA-15 and Cu-NbOx/SBA-15 catalysts were pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.jphotochem.2021.113726</td>\n",
       "      <td>Photocatalytic hydrogen production from alcoho...</td>\n",
       "      <td>Nanocomposites based on titanium dioxide loade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.cherd.2022.05.018</td>\n",
       "      <td>A text mining framework for screening catalyst...</td>\n",
       "      <td>Hydrogen production is an active area of resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.tet.2021.132473</td>\n",
       "      <td>Homogeneous first-row transition metal catalys...</td>\n",
       "      <td>The recent advances in homogeneous first-row t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DOI  \\\n",
       "0        10.1016/j.jcou.2022.101914   \n",
       "1      10.1016/j.cattod.2022.05.021   \n",
       "2  10.1016/j.jphotochem.2021.113726   \n",
       "3       10.1016/j.cherd.2022.05.018   \n",
       "4         10.1016/j.tet.2021.132473   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Hydrogen and alcohols production by Serratia s...   \n",
       "1  High-efficient production of fatty alcohol via...   \n",
       "2  Photocatalytic hydrogen production from alcoho...   \n",
       "3  A text mining framework for screening catalyst...   \n",
       "4  Homogeneous first-row transition metal catalys...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Climate change and its consequences have stimu...  \n",
       "1  Cu/SBA-15 and Cu-NbOx/SBA-15 catalysts were pr...  \n",
       "2  Nanocomposites based on titanium dioxide loade...  \n",
       "3  Hydrogen production is an active area of resea...  \n",
       "4  The recent advances in homogeneous first-row t...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load of pp\n",
    "df_h2 = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/elsevier_abstract.csv')\n",
    "df_h2 =  df_h2.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_h2.shape)\n",
    "df_h2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf08a82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (5900, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.adapen.2021.100069</td>\n",
       "      <td>Pressurized chemical looping methane reforming...</td>\n",
       "      <td>This study investigates the potential of apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.jclepro.2022.132649</td>\n",
       "      <td>An advanced coal-based zero-emission polygener...</td>\n",
       "      <td>To achieve different products distributions an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.jcat.2022.07.035</td>\n",
       "      <td>Methanol-to-olefins catalysis on window-cage t...</td>\n",
       "      <td>Catalyst lifetime and product selectivity of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.cej.2021.130835</td>\n",
       "      <td>Analysis of methanol synthesis using CO2 hydro...</td>\n",
       "      <td>Utilizing the greenhouse gas CO2 as a feedstoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.compchemeng.2022.107810</td>\n",
       "      <td>Techno-economic and environmental analysis of ...</td>\n",
       "      <td>The conventional configuration of a pulp mill,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "0       10.1016/j.adapen.2021.100069   \n",
       "1      10.1016/j.jclepro.2022.132649   \n",
       "2         10.1016/j.jcat.2022.07.035   \n",
       "3          10.1016/j.cej.2021.130835   \n",
       "4  10.1016/j.compchemeng.2022.107810   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Pressurized chemical looping methane reforming...   \n",
       "1  An advanced coal-based zero-emission polygener...   \n",
       "2  Methanol-to-olefins catalysis on window-cage t...   \n",
       "3  Analysis of methanol synthesis using CO2 hydro...   \n",
       "4  Techno-economic and environmental analysis of ...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  This study investigates the potential of apply...  \n",
       "1  To achieve different products distributions an...  \n",
       "2  Catalyst lifetime and product selectivity of m...  \n",
       "3  Utilizing the greenhouse gas CO2 as a feedstoc...  \n",
       "4  The conventional configuration of a pulp mill,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load of pp\n",
    "df_m2 = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/methanol_synthesis.csv')\n",
    "df_m2 =  df_m2.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_m2.shape)\n",
    "df_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03784ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net shape of data frame: (11800, 3)\n"
     ]
    }
   ],
   "source": [
    "# concatenating df1 and df2 along rows\n",
    "df_net_1 = pd.concat([df_h2,df_m2], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acdb3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_1['labels'] = 1  #Not relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e8b53ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net shape of data frame: (32881, 4)\n"
     ]
    }
   ],
   "source": [
    "# concatenating df1 and df2 along rows\n",
    "df_net_total = pd.concat([df_net, df_net_1], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c8b6aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame before: (32631, 4)\n",
      "Shape of data frame after: (31701, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1533/9781845697662.2.102</td>\n",
       "      <td>5 Pyrolysis for recycling waste composites</td>\n",
       "      <td>\\n               Pyrolysis is a suitable proce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.fuel.2021.120505</td>\n",
       "      <td>Low-pressure hydrothermal processing of mixed ...</td>\n",
       "      <td>The amount of polyolefin waste, which is 63% o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.conbuildmat.2022.127949</td>\n",
       "      <td>Cement mortars with ceramic molds shells and p...</td>\n",
       "      <td>Foundry industry produces millions of tons of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.arabjc.2022.104262</td>\n",
       "      <td>Degradation-fragmentation of marine plastic wa...</td>\n",
       "      <td>This review critically evaluates the plastic a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.conbuildmat.2019.117253</td>\n",
       "      <td>Performance of AC mixtures containing flakes o...</td>\n",
       "      <td>This paper evaluates the performance of asphal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "0        10.1533/9781845697662.2.102   \n",
       "1         10.1016/j.fuel.2021.120505   \n",
       "2  10.1016/j.conbuildmat.2022.127949   \n",
       "3       10.1016/j.arabjc.2022.104262   \n",
       "4  10.1016/j.conbuildmat.2019.117253   \n",
       "\n",
       "                                               Title  \\\n",
       "0        5 Pyrolysis for recycling waste composites    \n",
       "1  Low-pressure hydrothermal processing of mixed ...   \n",
       "2  Cement mortars with ceramic molds shells and p...   \n",
       "3  Degradation-fragmentation of marine plastic wa...   \n",
       "4  Performance of AC mixtures containing flakes o...   \n",
       "\n",
       "                                            Abstract  labels  \n",
       "0  \\n               Pyrolysis is a suitable proce...       0  \n",
       "1  The amount of polyolefin waste, which is 63% o...       0  \n",
       "2  Foundry industry produces millions of tons of ...       0  \n",
       "3  This review critically evaluates the plastic a...       0  \n",
       "4  This paper evaluates the performance of asphal...       0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the all entries with nan in abstract column\n",
    "NO_INDEX = []\n",
    "for i in range(len(df_net_total)):\n",
    "    if type(df_net_total.Abstract[i]) != float: \n",
    "        NO_INDEX.append(i)\n",
    "#Select some entries        \n",
    "df_net_total = df_net_total.iloc[NO_INDEX].reset_index(drop = True)\n",
    "print('Shape of data frame before:', df_net_total.shape)\n",
    "\n",
    "#Delete the all entries with integer in abstract column\n",
    "NO_INDEXX = []\n",
    "for i in range(len(df_net_total)):\n",
    "    if df_net_total.Abstract[i] != '0': \n",
    "        NO_INDEXX.append(i)\n",
    "#Select some entries        \n",
    "df_net_total = df_net_total.iloc[NO_INDEXX].reset_index(drop = True)\n",
    "print('Shape of data frame after:', df_net_total.shape)\n",
    "\n",
    "df_net_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00c33289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abstract cleaning\n",
    "def deletespace(text):\n",
    "    text0 = text.replace(\"<jats:p>\",\"\" )\n",
    "    text1 =  text0.replace(\"</jats:p>\", '')\n",
    "    text2 = text1.replace('<jats:title>Abstract</jats:title>\\n', '')\n",
    "    text3 = text2.replace('<p>', \"\")\n",
    "    text4 = text3.replace('</p>', \"\")\n",
    "    text5 = text4.replace('\\n', \"\")\n",
    "    \n",
    "    return text5\n",
    "df_net_total['Abstract'] = df_net_total['Abstract'].apply(deletespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "043271c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_net_total.sample(5000)\n",
    "df =  df_net_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba84c34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31701"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f418d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Abstract'].values\n",
    "labels = df['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c14434e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     do_lower_case = True\n",
    "#     )\n",
    "\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ixa-ehu/SciBERT-SQuAD-QuAC\",model_max_length=512)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"sschellhammer/SciTweets_SciBert\",model_max_length=512)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kauffinger/scibert_scivocab_uncased-mnli\", model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cfdab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════╤═════════════╕\n",
      "│ Tokens         │   Token IDs │\n",
      "╞════════════════╪═════════════╡\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ one            │         482 │\n",
      "├────────────────┼─────────────┤\n",
      "│ -              │         579 │\n",
      "├────────────────┼─────────────┤\n",
      "│ pot            │         985 │\n",
      "├────────────────┼─────────────┤\n",
      "│ process        │         624 │\n",
      "├────────────────┼─────────────┤\n",
      "│ combining      │        6484 │\n",
      "├────────────────┼─────────────┤\n",
      "│ trans          │         428 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ester        │        6575 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ification    │        1401 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ selective      │        5704 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hydrogen       │        5326 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ation        │         150 │\n",
      "├────────────────┼─────────────┤\n",
      "│ was            │         241 │\n",
      "├────────────────┼─────────────┤\n",
      "│ established    │        3452 │\n",
      "├────────────────┼─────────────┤\n",
      "│ to             │         147 │\n",
      "├────────────────┼─────────────┤\n",
      "│ produce        │        3299 │\n",
      "├────────────────┼─────────────┤\n",
      "│ biod           │       13240 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ies          │         301 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##el           │         154 │\n",
      "├────────────────┼─────────────┤\n",
      "│ from           │         263 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hem            │        2372 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##p            │       30121 │\n",
      "├────────────────┼─────────────┤\n",
      "│ (              │         145 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cannabis       │       23683 │\n",
      "├────────────────┼─────────────┤\n",
      "│ sati           │       20335 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##va           │        3833 │\n",
      "├────────────────┼─────────────┤\n",
      "│ l              │         152 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "├────────────────┼─────────────┤\n",
      "│ )              │         546 │\n",
      "├────────────────┼─────────────┤\n",
      "│ seed           │        3678 │\n",
      "├────────────────┼─────────────┤\n",
      "│ oil            │        4981 │\n",
      "├────────────────┼─────────────┤\n",
      "│ which          │         334 │\n",
      "├────────────────┼─────────────┤\n",
      "│ is             │         165 │\n",
      "├────────────────┼─────────────┤\n",
      "│ eliminated     │       10776 │\n",
      "├────────────────┼─────────────┤\n",
      "│ as             │         188 │\n",
      "├────────────────┼─────────────┤\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ potential      │        1411 │\n",
      "├────────────────┼─────────────┤\n",
      "│ feeds          │       24258 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##toc          │       18226 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##k            │       30135 │\n",
      "├────────────────┼─────────────┤\n",
      "│ by             │         214 │\n",
      "├────────────────┼─────────────┤\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ specification  │        6387 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ iodine         │       17907 │\n",
      "├────────────────┼─────────────┤\n",
      "│ value          │         973 │\n",
      "├────────────────┼─────────────┤\n",
      "│ (              │         145 │\n",
      "├────────────────┼─────────────┤\n",
      "│ iv             │        2448 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ;              │        1814 │\n",
      "├────────────────┼─────────────┤\n",
      "│ 120            │        5897 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##g            │       30123 │\n",
      "├────────────────┼─────────────┤\n",
      "│ i              │         259 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##2            │       30132 │\n",
      "├────────────────┼─────────────┤\n",
      "│ /              │        1352 │\n",
      "├────────────────┼─────────────┤\n",
      "│ 100            │        1287 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##g            │       30123 │\n",
      "├────────────────┼─────────────┤\n",
      "│ maximum        │        2050 │\n",
      "├────────────────┼─────────────┤\n",
      "│ )              │         546 │\n",
      "├────────────────┼─────────────┤\n",
      "│ contained      │        4482 │\n",
      "├────────────────┼─────────────┤\n",
      "│ in             │         121 │\n",
      "├────────────────┼─────────────┤\n",
      "│ en             │         279 │\n",
      "├────────────────┼─────────────┤\n",
      "│ 142            │       19845 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##14           │        1635 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "├────────────────┼─────────────┤\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ series         │        2568 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ alkaline       │       12835 │\n",
      "├────────────────┼─────────────┤\n",
      "│ earth          │        6732 │\n",
      "├────────────────┼─────────────┤\n",
      "│ metal          │        4353 │\n",
      "├────────────────┼─────────────┤\n",
      "│ oxides         │       20464 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ alkaline       │       12835 │\n",
      "├────────────────┼─────────────┤\n",
      "│ earth          │        6732 │\n",
      "├────────────────┼─────────────┤\n",
      "│ metal          │        4353 │\n",
      "├────────────────┼─────────────┤\n",
      "│ supported      │        2810 │\n",
      "├────────────────┼─────────────┤\n",
      "│ copper         │        8398 │\n",
      "├────────────────┼─────────────┤\n",
      "│ oxide          │        6678 │\n",
      "├────────────────┼─────────────┤\n",
      "│ were           │         267 │\n",
      "├────────────────┼─────────────┤\n",
      "│ prepared       │        4092 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ tested         │        2733 │\n",
      "├────────────────┼─────────────┤\n",
      "│ as             │         188 │\n",
      "├────────────────┼─────────────┤\n",
      "│ catalysts      │       15834 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "├────────────────┼─────────────┤\n",
      "│ sr             │        4193 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##o            │       30112 │\n",
      "├────────────────┼─────────────┤\n",
      "│ supported      │        2810 │\n",
      "├────────────────┼─────────────┤\n",
      "│ 10             │         566 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##wt           │        7097 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "├────────────────┼─────────────┤\n",
      "│ %              │        1863 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cu             │        4039 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##o            │       30112 │\n",
      "├────────────────┼─────────────┤\n",
      "│ showed         │        1367 │\n",
      "├────────────────┼─────────────┤\n",
      "│ the            │         111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ superior       │        5811 │\n",
      "├────────────────┼─────────────┤\n",
      "│ catalytic      │        8741 │\n",
      "├────────────────┼─────────────┤\n",
      "│ activity       │        1071 │\n",
      "├────────────────┼─────────────┤\n",
      "│ for            │         168 │\n",
      "├────────────────┼─────────────┤\n",
      "│ trans          │         428 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ester        │        6575 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ification    │        1401 │\n",
      "├────────────────┼─────────────┤\n",
      "│ with           │         190 │\n",
      "├────────────────┼─────────────┤\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ biod           │       13240 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ies          │         301 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##el           │         154 │\n",
      "├────────────────┼─────────────┤\n",
      "│ yield          │        2210 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ 96             │        7380 │\n",
      "├────────────────┼─────────────┤\n",
      "│ %              │        1863 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hydrogen       │        5326 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ation        │         150 │\n",
      "├────────────────┼─────────────┤\n",
      "│ with           │         190 │\n",
      "├────────────────┼─────────────┤\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ reduced        │        1797 │\n",
      "├────────────────┼─────────────┤\n",
      "│ iodine         │       17907 │\n",
      "├────────────────┼─────────────┤\n",
      "│ value          │         973 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ 113            │       14844 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ also           │         469 │\n",
      "├────────────────┼─────────────┤\n",
      "│ exhibited      │        5781 │\n",
      "├────────────────┼─────────────┤\n",
      "│ a              │         106 │\n",
      "├────────────────┼─────────────┤\n",
      "│ promising      │        6704 │\n",
      "├────────────────┼─────────────┤\n",
      "│ selectivity    │       10788 │\n",
      "├────────────────┼─────────────┤\n",
      "│ for            │         168 │\n",
      "├────────────────┼─────────────┤\n",
      "│ eliminating    │       15169 │\n",
      "├────────────────┼─────────────┤\n",
      "│ methyl         │        6090 │\n",
      "├────────────────┼─────────────┤\n",
      "│ lin            │        3158 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ole          │        2178 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##nat          │       12639 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##e            │       30107 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ increasing     │        1953 │\n",
      "├────────────────┼─────────────┤\n",
      "│ methyl         │        6090 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ole            │       14198 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ate          │         217 │\n",
      "├────────────────┼─────────────┤\n",
      "│ without        │        1319 │\n",
      "├────────────────┼─────────────┤\n",
      "│ rising         │       13563 │\n",
      "├────────────────┼─────────────┤\n",
      "│ methyl         │        6090 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ste            │        2038 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ara          │        4522 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##te           │         282 │\n",
      "├────────────────┼─────────────┤\n",
      "│ in             │         121 │\n",
      "├────────────────┼─────────────┤\n",
      "│ the            │         111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ selective      │        5704 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hydrogen       │        5326 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ation        │         150 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "├────────────────┼─────────────┤\n",
      "│ the            │         111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ fuel           │        8086 │\n",
      "├────────────────┼─────────────┤\n",
      "│ properties     │        1784 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ the            │         111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ selective      │        5704 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hydrogen       │        5326 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ated         │         224 │\n",
      "├────────────────┼─────────────┤\n",
      "│ methyl         │        6090 │\n",
      "├────────────────┼─────────────┤\n",
      "│ esters         │       20019 │\n",
      "├────────────────┼─────────────┤\n",
      "│ are            │         220 │\n",
      "├────────────────┼─────────────┤\n",
      "│ within         │        1017 │\n",
      "├────────────────┼─────────────┤\n",
      "│ biod           │       13240 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ies          │         301 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##el           │         154 │\n",
      "├────────────────┼─────────────┤\n",
      "│ specifications │        9806 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "├────────────────┼─────────────┤\n",
      "│ furthermore    │        2403 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ,              │         422 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cet            │       18013 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ane          │         840 │\n",
      "├────────────────┼─────────────┤\n",
      "│ numbers        │        3067 │\n",
      "├────────────────┼─────────────┤\n",
      "│ and            │         137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ iodine         │       17907 │\n",
      "├────────────────┼─────────────┤\n",
      "│ values         │         988 │\n",
      "├────────────────┼─────────────┤\n",
      "│ were           │         267 │\n",
      "├────────────────┼─────────────┤\n",
      "│ well           │         804 │\n",
      "├────────────────┼─────────────┤\n",
      "│ correlated     │        3968 │\n",
      "├────────────────┼─────────────┤\n",
      "│ with           │         190 │\n",
      "├────────────────┼─────────────┤\n",
      "│ the            │         111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ compositions   │       15416 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ the            │         111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hydrogen       │        5326 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ated         │         224 │\n",
      "├────────────────┼─────────────┤\n",
      "│ methyl         │        6090 │\n",
      "├────────────────┼─────────────┤\n",
      "│ esters         │       20019 │\n",
      "├────────────────┼─────────────┤\n",
      "│ according      │        1425 │\n",
      "├────────────────┼─────────────┤\n",
      "│ to             │         147 │\n",
      "├────────────────┼─────────────┤\n",
      "│ degrees        │        5634 │\n",
      "├────────────────┼─────────────┤\n",
      "│ of             │         131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ uns            │        6327 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##aturation    │       14052 │\n",
      "├────────────────┼─────────────┤\n",
      "│ .              │         205 │\n",
      "╘════════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence():\n",
    "    \n",
    "    '''Displays the tokens and respective IDs of a random text sample'''\n",
    "    index = random.randint(0, len(text)-1)\n",
    "    table = np.array([tokenizer.tokenize(text[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f35f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/home/user3/.local/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    '''\n",
    "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "    '''\n",
    "    return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 32,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in text:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e81b63d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  102,   111,   527,  1815,   106, 20640,  1139,   791,   191,   111,\n",
       "         4142, 11766,   145,  8806,   546,  2358,   168,   111,  2857,  5602,\n",
       "          131,  3967,  4756,  6882,   145, 10865,   546,   690,  8799,   579,\n",
       "         4765,   103])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5740096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════╤═════════════╤══════════════════╕\n",
      "│ Tokens      │   Token IDs │   Attention Mask │\n",
      "╞═════════════╪═════════════╪══════════════════╡\n",
      "│ [CLS]       │         102 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ in          │         121 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ the         │         111 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ last        │        2442 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ few         │        2149 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ decades     │        8148 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ,           │         422 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ the         │         111 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ development │        1120 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ of          │         131 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ biomass     │        7537 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ energy      │        1333 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ has         │         434 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ become      │        3063 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ a           │         106 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ key         │        1519 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ research    │         849 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ focus       │        1790 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ to          │         147 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ press       │        1588 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ the         │         111 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ emissions   │        8050 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ of          │         131 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ greenhouse  │       17403 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ gas         │        2704 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ .           │         205 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ syn         │         977 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ ##gas       │       12119 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ production  │        1865 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ from        │         263 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ biomass     │        7537 │                1 │\n",
      "├─────────────┼─────────────┼──────────────────┤\n",
      "│ [SEP]       │         103 │                1 │\n",
      "╘═════════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence_encoding():\n",
    "    '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
    "    index = random.randint(0, len(text) - 1)\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "    token_ids = [i.numpy() for i in token_id[index]]\n",
    "    attention = [i.numpy() for i in attention_masks[index]]\n",
    "\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b21667b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_ratio = 0.3\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d2bdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_tp(preds, labels):\n",
    "    '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "    '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "    '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "    '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "    '''\n",
    "    Returns the following metrics:\n",
    "    - accuracy    = (TP + TN) / N\n",
    "    - precision   = TP / (TP + FP)\n",
    "    - recall      = TP / (TP + FN)\n",
    "    - specificity = TN / (TN + FP)\n",
    "    '''\n",
    "    preds = np.argmax(preds, axis = 1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    tp = b_tp(preds, labels)\n",
    "    tn = b_tn(preds, labels)\n",
    "    fp = b_fp(preds, labels)\n",
    "    fn = b_fn(preds, labels)\n",
    "    b_accuracy = (tp + tn) / len(labels)\n",
    "    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "    return b_accuracy, b_precision, b_recall, b_specificity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c19396d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29113/3928200873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m model = AutoModelForSequenceClassification.from_pretrained(\"kauffinger/scibert_scivocab_uncased-mnli\",num_labels = 2,\n\u001b[1;32m     11\u001b[0m                                                             \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                             output_hidden_states = False)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# model = AutoModelForSequenceClassification.from_pretrained(\"sschellhammer/SciTweets_SciBert\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         raise ValueError(\n\u001b[1;32m    448\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1887\u001b[0m                     \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     \u001b[0msharded_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharded_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m                     \u001b[0m_fast_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m                 )\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init)\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "# Load the BertForSequenceClassification model\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     num_labels = 2,\n",
    "#     output_attentions = False,\n",
    "#     output_hidden_states = False,\n",
    "# )\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"kauffinger/scibert_scivocab_uncased-mnli\",num_labels = 2,\n",
    "                                                            output_attentions = False,\n",
    "                                                            output_hidden_states = False)\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"sschellhammer/SciTweets_SciBert\"\n",
    "#                                                            ,num_labels = 2,\n",
    "#                                                             output_attentions = False,\n",
    "#                                                             output_hidden_states = False)\n",
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr = 5e-5,\n",
    "                              eps = 1e-08\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Run on GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b10780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 10\n",
    "\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "    \n",
    "    # ========== Training ==========\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "          eval_output = model(b_input_ids, \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d949c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb74bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:                 Pyrolysis is a suitable process for recycling polymer composites because the thermal decomposition products of the polymer matrix evaporate, and thus the reinforcement materials can be recovered and reused. The products of pyrolysis carried out at an appropriate temperature are monomers and other valuable chemicals. This chapter describes the pyrolysis reactions and products of frequently used thermoplastics and thermosets in polymer composites. Published results on pyrolysis of various polymer composites are discussed in order to understand the requirements of successful plastic composite recycling by pyrolysis. The environmental concern related to pyrolysis of flame retardants containing polymer composites is also touched upon and some methods are referred to for decreasing or eliminating toxic and harmful compounds from the pyrolysis products of halogenated flame retardants.             \n",
      "\n",
      "Predicted Class:  relevant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "new_sentence = df_net_total['Abstract'][0]\n",
    "# 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n",
    "\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "prediction = 'relevant' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 0 else 'non-relavent'\n",
    "\n",
    "print('Input Sentence: ', new_sentence, \"\\n\")\n",
    "print('Predicted Class: ', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0331f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29113/1075571241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sschellhammer/SciTweets_SciBert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sschellhammer/SciTweets_SciBert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         raise ValueError(\n\u001b[1;32m    448\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1887\u001b[0m                     \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     \u001b[0msharded_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharded_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m                     \u001b[0m_fast_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m                 )\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/bart11/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init)\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sschellhammer/SciTweets_SciBert\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"sschellhammer/SciTweets_SciBert\", num_labels =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91d29974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090aa91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bart11",
   "language": "python",
   "name": "bart11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
