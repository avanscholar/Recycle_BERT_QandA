{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def17fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elsevier Libraries\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "\n",
    "#Libraries for URL access\n",
    "import json\n",
    "import csv\n",
    "import pprint\n",
    "import requests\n",
    "import xmltodict\n",
    "import urllib3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Import warnings library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml.etree.ElementTree â€” The ElementTree XML API\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = [] #Creating an empty list to store the  info\n",
    "#Rerunning this will delete the data that will be stored further\n",
    "#Run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a num array of 0 to 5900 spaces 100 apart per page. Each page of Search returns 100 entries until 6000 is reached\n",
    "num = np.linspace(0, 6000, 100, dtype = int)\n",
    "print(num)\n",
    "#Maximum of 6000 searches are returned on calling the ElsSearch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append \"apikey\" and \"insttoken\" as suggest in the ElsSearch document into a config file\n",
    "config = {\n",
    "    \"apikey\": \"Enter your API key\",\n",
    " \"insttoken\": \"Enter your institute token\"\n",
    "    }\n",
    "\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XML_DOI(link):\n",
    "    \n",
    "    #defining a header's dictionary to pass through requests\n",
    "    headers_dict = {\"X-ELS-APIKey\": \"Enter your API key\", \"X-ELS-Insttoken\": \"Enter your institute token\", \"Accept\": \"application/xml\"}\n",
    "    \n",
    "    #x takes response of the HTTP request, passes link\n",
    "    x = requests.get(link, headers=headers_dict)\n",
    "    \n",
    "    #Save it as XML file\n",
    "    with open(\"doi.xml\", 'wb') as f:\n",
    "        f.write(x.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38482585",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "\n",
    "#Loop to iterate over all papers\n",
    "#UPI query can take many arguments.\n",
    "#start, count, query are a few as name suggests\n",
    "for i in range(0, 60):\n",
    "    \n",
    "    start = \"https://api.elsevier.com/content/search/sciencedirect?\" \n",
    "    count = \"start=\" + str(num[i]) + \"&count=100\"\n",
    "    query = \"&query=waste+plastic+recycle+methods\"\n",
    "    endapi = \"&apiKey=Enter your API key&insttoken=Enter your institute token\"\n",
    "    \n",
    "    link = start + count + query  + endapi \n",
    "    #print(link)\n",
    "    link_list.append(link)\n",
    "#subscription = \"&subscribed=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27956494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the XML_DOI function\n",
    "for j in range(0, 60):\n",
    "    xmlfile = XML_DOI(link_list[j])\n",
    "    #Read the data\n",
    "    #<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    tree = ET.parse(r'doi.xml')\n",
    "    root = tree.getroot()\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "    \n",
    "        info_dict = {} #This will create a dictionary where we will store information about the searches\n",
    "    \n",
    "        '''\n",
    "        CHECK CODE\n",
    "        url = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text\n",
    "        title = entry.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "        pub_name = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "        doi = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi').text\n",
    "        #description = entry.find('{http://purl.org/dc/elements/1.1/}description').text\n",
    "        print(url, title, pub_name, doi)\n",
    "        print('\\n')\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        info_dict['URL'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text\n",
    "        info_dict['Title'] = entry.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "        info_dict['Pub_Name'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "        doi = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi')\n",
    "        if doi is None:\n",
    "            info_dict['DOI'] = None\n",
    "        else:\n",
    "            info_dict['DOI'] = doi.text\n",
    "    \n",
    "        info_list.append(info_dict)\n",
    "    \n",
    "    #print(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_list), len(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOI =  []\n",
    "Title = []\n",
    "Pub_name = []\n",
    "\n",
    "for i in range(6000):\n",
    "    DOI.append(info_list[i]['DOI'])\n",
    "    Title.append(info_list[i]['Title'])\n",
    "    Pub_name.append(info_list[i]['Pub_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.DataFrame()\n",
    "df['Title'] =  Title\n",
    "df['Pub_name'] = Pub_name\n",
    "df['DOI'] = DOI\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44caec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create string1 and string2 to join doi with institoken to make a single URL\n",
    "string1 = \"https://api.elsevier.com/content/article/doi/\" \n",
    "string2 = \"?apiKey=Enter your API key&insttoken=Enter your institute token\"\n",
    "\n",
    "#Access every DOI in the previous file and append the new URL to another column\n",
    "df['Link'] = df['DOI'].apply(lambda x: string1 + str(x) + string2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6efa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list_abstract = []\n",
    "list_doi= []\n",
    "list_title = []\n",
    "list_date = []\n",
    "list_journal = []\n",
    "\n",
    "## ScienceDirect (full-text) document example using DOI\n",
    "#for i in range(len(data)):\n",
    "from pprint import pprint\n",
    "doi= df['DOI']\n",
    "for i in range(df.shape[0]):\n",
    "    pprint(doi[i])\n",
    "    doi_doc = FullDoc(doi = doi[i])\n",
    "    if doi_doc.read(client):\n",
    "\n",
    "        #pprint(dir(doi_doc))\n",
    "        #pprint(doi_doc._data)\n",
    "        abstract = doi_doc._data['coredata']['dc:description']\n",
    "        title = doi_doc.title\n",
    "        date = doi_doc._data['coredata']['prism:coverDisplayDate']\n",
    "        journal = doi_doc._data['coredata']['prism:publicationName']\n",
    "        #pprint(abstract)\n",
    "        print(i, 'done')\n",
    "        #dict_abstract['DOI'] = doi[i]\n",
    "        #dict_abstract['Abstract'] = abstract\n",
    "        list_abstract.append(abstract)\n",
    "        list_doi.append(doi[i])\n",
    "        list_title.append(title)\n",
    "        list_date.append(date)\n",
    "        list_journal.append(journal)\n",
    "        #doi_doc.write()\n",
    "    \n",
    "    else:\n",
    "        pprint('Operation failed')\n",
    "        #dict_abstract['DOI'] = doi[i]\n",
    "        #dict_abstract['Abstract'] = 'NAN'\n",
    "        list_abstract.append('0')\n",
    "        list_doi.append('1')\n",
    "        list_title.append('2')\n",
    "        list_date.append('3')\n",
    "        list_journal.append('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available_abstract = pd.DataFrame()\n",
    "df_available_abstract['DOI'] = list_doi\n",
    "df_available_abstract['Title'] = list_title\n",
    "df_available_abstract['Abstract'] = list_abstract\n",
    "df_available_abstract['Date'] = list_date\n",
    "df_available_abstract['Journal'] = list_journal\n",
    "\n",
    "df_available_abstract.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available_abstract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available_abstract.to_csv('random_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05b7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
