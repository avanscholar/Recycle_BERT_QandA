{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BART1 environment\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "#Import nltk, download repositary for tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb33a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load of pet\n",
    "df_pet = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/pet_recycles.csv')\n",
    "df_pet =  df_pet.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pet.shape)\n",
    "df_pet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e01217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load of ps\n",
    "df_ps = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/PS_recycle_methods.csv')\n",
    "#df_ps =  df_ps.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_ps.shape)\n",
    "df_ps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load of pe\n",
    "df_pe = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/PE_RECYCLE_METHODS.csv')\n",
    "df_pe =  df_pe.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pe.shape)\n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load of pp\n",
    "df_pp = pd.read_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/pp_recycle.csv')\n",
    "#df_pp =  df_pp.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pp.shape)\n",
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating df1 and df2 along rows\n",
    "df_net = pd.concat([df_pe, df_pet,df_pp, df_ps], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indddd = []\n",
    "for i in range(len(df_net)):\n",
    "    if int(df_net.Date[i][-4:]) in [2023,2022,2021,2020,2019,2018,2017]:\n",
    "        indddd.append(i)\n",
    "len(indddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f13925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net = df_net.iloc[indddd].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d941134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the all entries with nan in abstract column\n",
    "NO_INDEX = []\n",
    "for i in range(len(df_net)):\n",
    "    if type(df_net.Abstract[i]) != float: \n",
    "        NO_INDEX.append(i)\n",
    "#Select some entries        \n",
    "df_net = df_net.iloc[NO_INDEX].reset_index(drop = True)\n",
    "print('Shape of data frame before:', df_net.shape)\n",
    "\n",
    "#Delete the all entries with integer in abstract column\n",
    "NO_INDEXX = []\n",
    "for i in range(len(df_net)):\n",
    "    if df_net.Abstract[i] != '0': \n",
    "        NO_INDEXX.append(i)\n",
    "#Select some entries        \n",
    "df_net = df_net.iloc[NO_INDEXX].reset_index(drop = True)\n",
    "print('Shape of data frame after:', df_net.shape)\n",
    "\n",
    "df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b26bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abstract cleaning\n",
    "def deletespace(text):\n",
    "    text0 = text.replace(\"<jats:p>\",\"\" )\n",
    "    text1 =  text0.replace(\"</jats:p>\", '')\n",
    "    text2 = text1.replace('<jats:title>Abstract</jats:title>\\n', '')\n",
    "    text3 = text2.replace('<p>', \"\")\n",
    "    text4 = text3.replace('</p>', \"\")\n",
    "    text5 = text4.replace('\\n', \"\")\n",
    "    \n",
    "    return text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4670ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net['Abstract'] = df_net['Abstract'].apply(deletespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9934f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of data:\", df_net.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20abed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_net = df_net.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edd52e",
   "metadata": {},
   "source": [
    "**Screener for all categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_har = pd.read_csv(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_full-modified.csv\",encoding=\"ISO-8859-1\")\n",
    "df_har.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pus =  pd.read_excel(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_full.xlsx\")\n",
    "df_pus.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62479a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = pd.concat([df_har.loc[:10000],df_pus.loc[10001:]], axis= 0).reset_index()\n",
    "df_mod.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b96b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod[\"Product\"][1459] = str(['bioenergy', 'energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod =df_mod.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61518d2f",
   "metadata": {},
   "source": [
    "**Create the listss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_mod[\"process\"].values\n",
    "process_ent=[]\n",
    "List=[]\n",
    "for i in range(len(df_mod)):\n",
    "    #print(x[i], i)\n",
    "    lis = x[i].split('[')\n",
    "    gis = lis[1].split(']')\n",
    "    his = gis[0].split(\"'\")\n",
    "    J=[]\n",
    "    for k in range(1, len(his)-1):\n",
    "        if(his[k]!=' '):\n",
    "            J.append(his[k])\n",
    "    List.append(J)\n",
    "    \n",
    "\n",
    "    \n",
    "for i in range(0, len(List)):\n",
    "    for j in range(0, len(List[i])):\n",
    "        v=List[i][j]\n",
    "        if(process_ent.count(v)==0):\n",
    "            process_ent.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b18a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_mod[\"catalyst\"].values\n",
    "catalyst_ent=[]\n",
    "List=[]\n",
    "for i in range(len(df_mod)):\n",
    "    lis = x[i].split('[')\n",
    "    gis = lis[1].split(']')\n",
    "    his = gis[0].split(\"'\")\n",
    "    J=[]\n",
    "    for k in range(1, len(his)-1):\n",
    "        if(his[k]!=' '):\n",
    "            J.append(his[k])\n",
    "    List.append(J)\n",
    "    \n",
    "for i in range(0, len(List)):\n",
    "    for j in range(0, len(List[i])):\n",
    "        v=List[i][j]\n",
    "        if(catalyst_ent.count(v)==0):\n",
    "            catalyst_ent.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7146a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_mod[\"Method\"].values\n",
    "method_ent=[]\n",
    "List=[]\n",
    "for i in range(len(df_mod)):\n",
    "    lis = x[i].split('[')\n",
    "    gis = lis[1].split(']')\n",
    "    his = gis[0].split(\"'\")\n",
    "    J=[]\n",
    "    for k in range(1, len(his)-1):\n",
    "        if(his[k]!=' '):\n",
    "            J.append(his[k])\n",
    "    List.append(J)\n",
    "    \n",
    "for i in range(0, len(List)):\n",
    "    for j in range(0, len(List[i])):\n",
    "        v=List[i][j]\n",
    "        if(method_ent.count(v)==0):\n",
    "            method_ent.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5be7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_mod[\"Product\"].values\n",
    "product_ent=[]\n",
    "List=[]\n",
    "for i in range(len(df_mod)):\n",
    "    #print(x[i],i)\n",
    "    lis = x[i].split('[')\n",
    "    gis = lis[1].split(']')\n",
    "    his = gis[0].split(\"'\")\n",
    "    J=[]\n",
    "    for k in range(1, len(his)-1):\n",
    "        if(his[k]!=' '):\n",
    "            J.append(his[k])\n",
    "    List.append(J)\n",
    "    \n",
    "for i in range(0, len(List)):\n",
    "    for j in range(0, len(List[i])):\n",
    "        v=List[i][j]\n",
    "        if(product_ent.count(v)==0):\n",
    "            product_ent.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_mod[\"reactant\"].values\n",
    "reactant_ent=[]\n",
    "List=[]\n",
    "for i in range(len(df_mod)):\n",
    "    lis = x[i].split('[')\n",
    "    gis = lis[1].split(']')\n",
    "    his = gis[0].split(\"'\")\n",
    "    J=[]\n",
    "    for k in range(1, len(his)-1):\n",
    "        if(his[k]!=' '):\n",
    "            J.append(his[k])\n",
    "    List.append(J)\n",
    "    \n",
    "for i in range(0, len(List)):\n",
    "    for j in range(0, len(List[i])):\n",
    "        v=List[i][j]\n",
    "        if(reactant_ent.count(v)==0):\n",
    "            reactant_ent.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Unique entries: \", len(product_ent))\n",
    "print(\"Unique entries product: \", len(product_ent))\n",
    "print(\"Unique entries method: \", len(method_ent))\n",
    "print(\"Unique entries reactant: \", len(reactant_ent))\n",
    "print(\"Unique entries catalyst: \", len(catalyst_ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93defa40",
   "metadata": {},
   "source": [
    "**Extraction of process parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "  \n",
    "# Load English tokenizer, tagger, \n",
    "# parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Custom dictionary of process parameters\n",
    "# process = ['temperature', 'pressure', 'weight', 'concentration']\n",
    "\n",
    "# replacements = {'K': 'kelvin', 'atm': 'pressure',\n",
    "#                '°C': 'celcius','bar': 'pressure',\n",
    "#                 'g' : 'gram','Mpa': 'pressure',\n",
    "#                 'pa' : 'pressure', \"MPa\": \"pressure\"}\n",
    "# #Help in dealing with units of parameters\n",
    "# replacer = replacements.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(replacements.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractprocess(text):\n",
    "#     sents =  sent_tokenize(text)\n",
    "#     proc = [] \n",
    "#     for sen in sents:\n",
    "#         for pro in process+list(replacements.keys()):\n",
    "#             import re\n",
    "#             if pro in sen:\n",
    "#                 sentence_word = nltk.word_tokenize(sen)\n",
    "#                 sentence_list = [replacer(n, n) for n in sentence_word]\n",
    "#                 sentence_list = \" \".join(sentence_list)\n",
    "#                 doc = nlp(sen)\n",
    "#                 x = re.findall('[0-9]+', sen)\n",
    "\n",
    "#                 for num in x:\n",
    "#                     for j in range(len(sentence_word)):\n",
    "\n",
    "#                         if num in sentence_word[j]:\n",
    "\n",
    "#                             for pro in process+list(replacements.keys()):\n",
    "\n",
    "#                                 if pro in nltk.word_tokenize(sentence_list)[j:j+2]:\n",
    "\n",
    "#                                     proc.append(\" \".join(sentence_word[j:j+2]))\n",
    "                                    \n",
    "#     return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_net['process'] = df_net['Abstract'].apply(extractprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23363b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Delete same entries\n",
    "# def deleteduplicate(lisst):\n",
    "#     listsss =  []\n",
    "#     [listsss.append(li) for li in lisst if li not in listsss]\n",
    "#     return listsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5efab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_net['process'] =  df_net['process'].apply(deleteduplicate)  #estimate time 20msec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Stopwords removal\n",
    "# from gensim.parsing.preprocessing import remove_stopwords\n",
    "# def deletestopwords(listt):\n",
    "#     actual_reactant = []\n",
    "#     for wrd in listt:\n",
    "#         filtered_sentencee = remove_stopwords(wrd)\n",
    "#         actual_reactant.append(filtered_sentencee)\n",
    "#     return actual_reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ba953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_net['process'] =  df_net['process'].apply(deletestopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4567549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indd = []\n",
    "# for i,cata in enumerate(df_net['process']):\n",
    "#     if len(cata) != 0:\n",
    "#         indd.append(i)\n",
    "        \n",
    "# len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pr = df_net.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2001f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pr.to_csv('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_pro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d9b7f",
   "metadata": {},
   "source": [
    "**Extraction of catalyst entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587119d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported chemical entity extraction library\n",
    "import chemdataextractor\n",
    "from chemdataextractor import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All chemical entities of catalyst\n",
    "df_cat =  pd.read_csv(r'/home/user3/Documents/avan_phd/objective_escape/catalys_entit_final.csv')\n",
    "df_cat =  df_cat.drop(['Unnamed: 0', 'frequency', 'Unnamed: 3', '7738'], axis= 1)\n",
    "df_cat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017843b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16315172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The exact catalyst entities\n",
    "cata = list(df_cat['section name'])\n",
    "print(\"Total unique entries of catalyst:\",len(cata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter all non-catalyst entities\n",
    "def catalystentities(text):\n",
    "    name_catalyst =  []\n",
    "    comp = []\n",
    "    if ('catalyst' in text.lower()) or ('catalysts' in text.lower()):\n",
    "        cataa = []\n",
    "        doc = Document(text)\n",
    "        ent = doc.cems\n",
    "        for i in range(len(ent)):\n",
    "            comp.append(ent[i].text)\n",
    "            doc = nlp(text)\n",
    "            for chunk in doc.noun_chunks:\n",
    "                for wrd in word_tokenize(chunk.text):\n",
    "                    for cat in comp:\n",
    "                        if (cat in cata):\n",
    "                            if cat in wrd:\n",
    "                                cataa.append(wrd)                            \n",
    "    else:\n",
    "        cataa = []\n",
    "                                \n",
    "    \n",
    "    name_catalyst.append(cataa)                           \n",
    "    return cataa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_net['catalyst'] =  df_net['Abstract'].apply(catalystentities)    #estimate time 56sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bf00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete same entries\n",
    "def deleteduplicate(lisst):\n",
    "    listsss =  []\n",
    "    [listsss.append(li) for li in lisst if li not in listsss]\n",
    "    \n",
    "    return listsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_net['catalyst'] =  df_net['catalyst'].apply(deleteduplicate)  #estimate time 20msec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b57705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "def deletestopwords(listt):\n",
    "    actual_reactant = []\n",
    "    for wrd in listt:\n",
    "        filtered_sentencee = remove_stopwords(wrd)\n",
    "        actual_reactant.append(filtered_sentencee)\n",
    "    return actual_reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_net['catalyst'] =  df_net['catalyst'].apply(deletestopwords)  #estimate time 20msec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb899ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data\",len(df_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38913a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(df_net['catalyst']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cat = df.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cat.to_csv('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_cat_1136.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a69a1",
   "metadata": {},
   "source": [
    "**Extraction of Reactant (polymer waste)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d795cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"polyethylene\",\"waste\",\"plastic\", 'PET', 'wastes' ]   #We will try this words\n",
    "j = 0\n",
    "def reactantextract(text):\n",
    "    reactants =  ['poly', 'waste', \"wastes\", \"plastic\", \"plastics\"]\n",
    "#     print(j,\"is done\")\n",
    "    reactant = []\n",
    "    for sen in sent_tokenize(text):\n",
    "#         if \"poly\" in sen:          #Keep it neutral(no biasing)\n",
    "        doc = nlp(sen)\n",
    "        for a, chunk in enumerate(doc.noun_chunks):\n",
    "            for react in reactants:\n",
    "                if react in reactant_ent:\n",
    "                    if react in chunk.text:\n",
    "                        reactant.append(chunk.text)\n",
    "                    \n",
    "    return reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dff['reactant'] =  dff['Abstract'].apply(reactantextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteduplicate(lisst):\n",
    "    listsss =  []\n",
    "    [listsss.append(li) for li in lisst if li not in listsss]\n",
    "    \n",
    "    return listsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df002f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dff['reactant'] =  dff['reactant'].apply(deleteduplicate) #estimate time 7 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8afe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['reactant'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "def deletestopwords(listt):\n",
    "    actual_reactant = []\n",
    "    for wrd in listt:\n",
    "        filtered_sentencee = remove_stopwords(wrd)\n",
    "        actual_reactant.append(filtered_sentencee)\n",
    "    return actual_reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cca09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['reactant'] =  dff['reactant'].apply(deletestopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fb3a3",
   "metadata": {},
   "source": [
    "**Methodology entities extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b135ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Three list of keywords\n",
    "methods =   ['pyrolysis','conversion',\"depolymerization\",\"degradation\", \"hydrolysis\",\"chemical conversion\",\"reforming\",\n",
    "             \"glycolysis\",\"thermal\"]\n",
    "\n",
    "# reactants = [\"polyethylene\",\"waste\",\"plastic\", 'PET', 'wastes' ]\n",
    "\n",
    "products = [\"ethylene glycol\",\"terephthalic acid\", \"Terephthalonitrile\",\"BHET\",\"Liquid\",\n",
    "            \"monomer\", \"products\", 'added', 'energy', 'CH3CHO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methodextract(text):\n",
    "    reactant = []\n",
    "    for sen in sent_tokenize(text):\n",
    "        for meth in methods:\n",
    "            if meth in method_ent:\n",
    "                if meth in sen:\n",
    "                    doc = nlp(sen)\n",
    "                    for a, chunk in enumerate(doc.noun_chunks):\n",
    "                        if meth in chunk.text:\n",
    "                            reactant.append(chunk.text)\n",
    "                        else:\n",
    "                            reactant.append(meth)\n",
    "\n",
    "    return reactant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c340565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteduplicate(lisst):\n",
    "    listsss =  []\n",
    "    [listsss.append(li) for li in lisst if li not in listsss]\n",
    "    \n",
    "    return listsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e562685",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dff['Method'] =  dff['Abstract'].apply(methodextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a88dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Method'] = dff['Method'].apply(deleteduplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Method'] = dff['Method'].apply(deletestopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fb440",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['Method']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6516cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meth = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meth.to_csv('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_meth.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6129d1c",
   "metadata": {},
   "source": [
    "**Extraction of products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"propylene\" in \"polypropylene\"\n",
    "dff = df_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69073bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list of keywords\n",
    "\n",
    "products_pet = [\"ethylene glycol\",\"terephthalic acid\", \"Terephthalonitrile\",\"BHET\",\"Liquid\",\n",
    "            \"monomer\", \"product\", 'added', 'energy', 'CH3CHO',\"mortar\"]\n",
    "products_ps = [\"styrene\", \"monomers\", \"monomer\",\"other valuable chemcials\", \"concrete\",\"bitumen\",\"oil\",\"oils\", \n",
    "               \"HIPS membranes\",'low-molecular' ]\n",
    "products_pe = [\"high-performance\", \"PU adhesive\", \"sand concrete\",\"HAC\",\"hydroxyapatite\" ]\n",
    "\n",
    "products_pp = [\"fibers\",\"fibre\",\"food containers\"]\n",
    "\n",
    "#\"matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6dbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_product =  products_pet + products_ps + products_pe + products_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30168bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def productextract(text):\n",
    "    product = []\n",
    "    for sen in sent_tokenize(text):\n",
    "        for prod in net_product:\n",
    "            if prod in product_ent:\n",
    "                if prod in sen:\n",
    "                    doc = nlp(sen)\n",
    "                    for a, chunk in enumerate(doc.noun_chunks):\n",
    "                        if prod in chunk.text:\n",
    "                            product.append(chunk.text)\n",
    "    #                     else:\n",
    "    #                         product.append(prod)\n",
    "                        \n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dff['Product'] =  dff['Abstract'].apply(productextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Product'] = dff['Product'].apply(deleteduplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Product'] = dff['Product'].apply(deletestopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dad91d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Product'][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['Product']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prod = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prod.to_csv('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f33196",
   "metadata": {},
   "outputs": [],
   "source": [
    "indee = []\n",
    "for d in dff.index:\n",
    "    if (len(dff['process'][d]) != 0) and (len(dff['catalyst'][d]) != 0) and (len(dff['reactant'][d]) != 0) and (len(dff['Method'][d]) != 0) and (len(dff['Product'][d]) != 0):\n",
    "        indee.append(d)\n",
    "        \n",
    "len(indee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_ff.to_csv('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/harshita/data_full_paper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['process'] = dff['process'].apply(deleteduplicate)\n",
    "dff['Product'] = dff['Product'].apply(deleteduplicate)\n",
    "dff['reactant'] = dff['reactant'].apply(deleteduplicate)\n",
    "dff[\"Method\"] = dff['Method'].apply(deleteduplicate)\n",
    "dff['catalyst'] = dff['catalyst'].apply(deleteduplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1b3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e400eda1",
   "metadata": {},
   "source": [
    "**1. QnA for catalyst**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9406fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['catalyst']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5231ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_ind[3004:3100]+indd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_cat = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b947e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dff_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fea8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeeee = []\n",
    "for i in range(len(data)):\n",
    "    if int(data.Date[i][-4:]) == 2023:\n",
    "        if len(data.catalyst[i]) != 0:\n",
    "            \n",
    "            indeeee.append(i)\n",
    "len(indeeee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[indeeee].reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(len(data)):\n",
    "    if len(data['catalyst'][i]) != 0:\n",
    "        #print(data['catalyst'][i])\n",
    "        for catt in data['catalyst'][i]:\n",
    "            y.append(catt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# matplotlib library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ''.join([str(i) for i in y])\n",
    "\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=3,\n",
    "                      max_font_size = 40)\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()\n",
    "\n",
    "plt.imshow(wordcloud) # image show\n",
    "plt.axis('off') # to off the axis of x and y\n",
    "plt.savefig('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/catalyst_2023.pdf',dpi=2000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47693a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from matplotlib import rc\n",
    "\n",
    "#Utilize the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Import the warning library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function for get the name of chemical entities and their frequency\n",
    "def get_chemical_entry_count(column, size):\n",
    "    catal = []\n",
    "    #Remove the all punctution\n",
    "    catalyst_column= pd.Series(column).str.replace('[^\\w\\s]','')\n",
    "    for i in range(size):\n",
    "        cat_list = catalyst_column[i].split(\" \")\n",
    "        for j in range(len(cat_list)):\n",
    "            #Appending the catalyst\n",
    "            catal.append(cat_list[j])\n",
    "            #frequency of existence\n",
    "            unique, frequency = np.unique(np.array(catal), return_counts = True)\n",
    "            #Making data frame of uniqueness and frequency\n",
    "            df_unique_counts = pd.DataFrame({'section name' : unique, 'frequency' : frequency})\n",
    "            \n",
    "    return df_unique_counts\n",
    "\n",
    "#Call the defined function\n",
    "df_cat_freq = get_chemical_entry_count(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3969a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the data frame based on frequency available\n",
    "sort = df_cat_freq.sort_values(\"frequency\", axis = 0, ascending = False).reset_index(drop = True)\n",
    "#print(Number of unique chemicals)\n",
    "print('Number of unique chemicals:', sort.shape[0])\n",
    "#Shows the first 5 rows\n",
    "sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b85e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2020\n",
    "df_list_catalyst = sort\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e28e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017\n",
    "df_list_catalyst17 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81efdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "df_list_catalyst18 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c56d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "df_list_catalyst19 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb485e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2021\n",
    "df_list_catalyst1 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022\n",
    "df_list_catalyst2 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1574ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023\n",
    "df_list_catalyst3 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a610f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n",
    "\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts1 = df_list_catalyst1.frequency\n",
    "tokens1 = df_list_catalyst1['section name']\n",
    "\n",
    "ranks1 = np.arange(1, len(counts1)+1)\n",
    "indices1 = argsort(-counts1)\n",
    "frequencies1 = counts1[indices1]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts2 = df_list_catalyst2.frequency\n",
    "tokens2 = df_list_catalyst2['section name']\n",
    "\n",
    "ranks2 = np.arange(1, len(counts2)+1)\n",
    "indices2 = argsort(-counts2)\n",
    "frequencies2 = counts2[indices2]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts3 = df_list_catalyst3.frequency\n",
    "tokens3 = df_list_catalyst3['section name']\n",
    "\n",
    "ranks3 = np.arange(1, len(counts3)+1)\n",
    "indices3 = argsort(-counts3)\n",
    "frequencies3 = counts3[indices3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda42a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A zipf line plot is shown\n",
    "counts17 = df_list_catalyst17.frequency\n",
    "tokens17 = df_list_catalyst17['section name']\n",
    "\n",
    "ranks17 = np.arange(1, len(counts17)+1)\n",
    "indices17 = argsort(-counts17)\n",
    "frequencies17 = counts17[indices17]\n",
    "\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts18 = df_list_catalyst18.frequency\n",
    "tokens18 = df_list_catalyst18['section name']\n",
    "\n",
    "ranks18 = np.arange(1, len(counts18)+1)\n",
    "indices18 = argsort(-counts18)\n",
    "frequencies18 = counts18[indices18]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts19 = df_list_catalyst19.frequency\n",
    "tokens19 = df_list_catalyst19['section name']\n",
    "\n",
    "ranks19 = np.arange(1, len(counts19)+1)\n",
    "indices19 = argsort(-counts19)\n",
    "frequencies19 = counts19[indices19]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,10**5)\n",
    "plt.xlim(1,10**3)\n",
    "\n",
    "loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2020')\n",
    "\n",
    "\n",
    "\n",
    "xlabel(\"Rank of catalyst entity\",fontweight='bold', fontsize=16)\n",
    "ylabel(\"Absolute frequency of catalyst entity\",fontweight='bold', fontsize=16)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12, rotation = 'vertical')\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts1)-2), 25).astype(int)):\n",
    "    dummy1 = text(ranks1[n], frequencies1[n], \" \" + tokens1[indices1[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12, rotation = 'vertical')\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts2)-2), 25).astype(int)):\n",
    "    dummy2 = text(ranks2[n], frequencies2[n], \" \" + tokens2[indices2[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12, rotation = 'vertical')\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts3)-2), 25).astype(int)):\n",
    "    dummy3 = text(ranks3[n], frequencies3[n], \" \" + tokens3[indices3[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12, rotation = 'vertical')\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/zipf_catalyst_text.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,1*10**1)\n",
    "plt.xlim(0.8,1*10**2)\n",
    "\n",
    "# loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "# loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "# loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2023')\n",
    "# loglog(ranks19, frequencies19, marker=\".\", label = '2019')\n",
    "# loglog(ranks18, frequencies18, marker=\".\", label = '2018')\n",
    "# loglog(ranks17, frequencies17, marker=\".\", label = '2017')\n",
    "\n",
    "\n",
    "xlabel(\"Rank of catalyst entity\",fontweight='bold', fontsize=21)\n",
    "ylabel(\"Absolute frequency of catalyst entity\",fontweight='bold', fontsize=21)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=18,rotation ='vertical')\n",
    "    \n",
    "    \n",
    "# for n in list(logspace(-0.5, log10(len(counts17)-2), 25).astype(int)):\n",
    "#     dummy2 = text(ranks17[n], frequencies17[n], \" \" + tokens17[indices17[n]], \n",
    "#                  verticalalignment=\"bottom\",\n",
    "#                  horizontalalignment=\"left\", fontweight='bold',\n",
    "#                  fontsize=18, rotation ='vertical')\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/zipf_catalyst_text_2023.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff_cat['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat = {}   #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho= {} #Dict for method question\n",
    "    dictt_prod = {} #Dict for product question\n",
    "    \n",
    "    #The data making for the catalyst entries\n",
    "    comp =  dff_cat['catalyst'][inde]\n",
    "    if len(comp) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_cat[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_cat[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the materials used as catalyst?\"]   #Question write here\n",
    "        dictt_cat[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_cat = answers(inde, abst,comp)\n",
    "        j = j+1\n",
    "    elif len(comp) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_cat[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_cat[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the materials used as catalyst?\"] \n",
    "        dictt_cat[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_cat =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "    \n",
    "    \n",
    "    dictt_cat[\"answers\"] = listttt_cat\n",
    "#     dictt_react[\"answers\"] = listttt_react\n",
    "#     dictt_metho[\"answers\"] = listttt_metho\n",
    "#     dictt_prod[\"answers\"]  = listttt_prod\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "    lisst.append(dictt_cat)\n",
    "#     lisst.append(dictt_react)\n",
    "#     lisst.append(dictt_metho)\n",
    "#     lisst.append(dictt_prod)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41a757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(0.80*(len(train)))]                       # 80% train\n",
    "valid_ = train[int(0.80*(len(train))):int(0.90*(len(train)))] #10% valid \n",
    "test_  = train[int(0.90*(len(train))):]                       #10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_), len(test_), len(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/cat_train.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2164f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/cat_test.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/cat_valid.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/catalyst/cat_full.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1e9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d5c5b85",
   "metadata": {},
   "source": [
    "**2. QnA for reactant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22784e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['reactant']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c845b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_ind[3004:3100]+indd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_react = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dff_react"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb09ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeeee = []\n",
    "for i in range(len(data)):\n",
    "    if int(data.Date[i][-4:]) == 2017:\n",
    "        if len(data.catalyst[i]) != 0:\n",
    "            indeeee.append(i)\n",
    "            \n",
    "len(indeeee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[indeeee].reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(len(data)):\n",
    "    if len(data['reactant'][i]) != 0:\n",
    "        #print(data['catalyst'][i])\n",
    "        for catt in data['reactant'][i]:\n",
    "            y.append(catt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# matplotlib library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ''.join([str(i) for i in y])\n",
    "\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=3,\n",
    "                      max_font_size = 40)\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()\n",
    "\n",
    "plt.imshow(wordcloud) # image show\n",
    "plt.axis('off') # to off the axis of x and y\n",
    "plt.savefig('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/reactant_2017.pdf',dpi=2000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163570b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from matplotlib import rc\n",
    "\n",
    "#Utilize the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Import the warning library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function for get the name of chemical entities and their frequency\n",
    "def get_chemical_entry_count(column, size):\n",
    "    catal = []\n",
    "    #Remove the all punctution\n",
    "    catalyst_column= pd.Series(column).str.replace('[^\\w\\s]','')\n",
    "    for i in range(size):\n",
    "        cat_list = catalyst_column[i].split(\" \")\n",
    "        for j in range(len(cat_list)):\n",
    "            #Appending the catalyst\n",
    "            catal.append(cat_list[j])\n",
    "            #frequency of existence\n",
    "            unique, frequency = np.unique(np.array(catal), return_counts = True)\n",
    "            #Making data frame of uniqueness and frequency\n",
    "            df_unique_counts = pd.DataFrame({'section name' : unique, 'frequency' : frequency})\n",
    "            \n",
    "    return df_unique_counts\n",
    "\n",
    "#Call the defined function\n",
    "df_cat_freq = get_chemical_entry_count(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the data frame based on frequency available\n",
    "sort = df_cat_freq.sort_values(\"frequency\", axis = 0, ascending = False).reset_index(drop = True)\n",
    "#print(Number of unique chemicals)\n",
    "print('Number of unique chemicals:', sort.shape[0])\n",
    "#Shows the first 5 rows\n",
    "sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2020\n",
    "df_list_catalyst = sort\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2021\n",
    "df_list_catalyst1 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33346f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022\n",
    "df_list_catalyst2 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023\n",
    "df_list_catalyst3 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n",
    "\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts1 = df_list_catalyst1.frequency\n",
    "tokens1 = df_list_catalyst1['section name']\n",
    "\n",
    "ranks1 = np.arange(1, len(counts1)+1)\n",
    "indices1 = argsort(-counts1)\n",
    "frequencies1 = counts1[indices1]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts2 = df_list_catalyst2.frequency\n",
    "tokens2 = df_list_catalyst2['section name']\n",
    "\n",
    "ranks2 = np.arange(1, len(counts2)+1)\n",
    "indices2 = argsort(-counts2)\n",
    "frequencies2 = counts2[indices2]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts3 = df_list_catalyst3.frequency\n",
    "tokens3 = df_list_catalyst3['section name']\n",
    "\n",
    "ranks3 = np.arange(1, len(counts3)+1)\n",
    "indices3 = argsort(-counts3)\n",
    "frequencies3 = counts3[indices3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,10**3)\n",
    "plt.xlim(1,0.5*10**4)\n",
    "\n",
    "loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2020')\n",
    "\n",
    "\n",
    "\n",
    "xlabel(\"Rank of reactant entity\",fontweight='bold', fontsize=16)\n",
    "ylabel(\"Absolute frequency of reactant entity\",fontweight='bold', fontsize=16)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts1)-2), 25).astype(int)):\n",
    "    dummy1 = text(ranks1[n], frequencies1[n], \" \" + tokens1[indices1[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts2)-2), 25).astype(int)):\n",
    "    dummy2 = text(ranks2[n], frequencies2[n], \" \" + tokens2[indices2[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts3)-2), 25).astype(int)):\n",
    "    dummy3 = text(ranks3[n], frequencies3[n], \" \" + tokens3[indices3[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/zipf_reactant_text.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13581143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,0.2*10**3)\n",
    "plt.xlim(0.9,0.2*10**3)\n",
    "\n",
    "# loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "# loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "# loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2017')\n",
    "\n",
    "\n",
    "\n",
    "xlabel(\"Rank of reactant entity\",fontweight='bold', fontsize=21)\n",
    "ylabel(\"Absolute frequency of reactant entity\",fontweight='bold', fontsize=21)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=18, rotation= 'vertical')\n",
    "    \n",
    "\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/zipf_reactant_text_2017.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_react.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff_react['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat = {}   #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho= {} #Dict for method question\n",
    "    dictt_prod = {} #Dict for product question\n",
    "    \n",
    "    #The data making for the catalyst entries\n",
    "    react =  dff_react['reactant'][inde]\n",
    "    if len(react) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_react[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_react[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the reactants used?\"]   #Question write here\n",
    "        dictt_react[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_react = answers(inde, abst,react)\n",
    "        j = j+1\n",
    "    elif len(react) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_react[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_react[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the reactants used?\"] \n",
    "        dictt_react[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_react =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "\n",
    "    \n",
    "    \n",
    "#     dictt_cat[\"answers\"] = listttt_cat\n",
    "    dictt_react[\"answers\"] = listttt_react\n",
    "#     dictt_metho[\"answers\"] = listttt_metho\n",
    "#     dictt_prod[\"answers\"]  = listttt_prod\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "#     lisst.append(dictt_cat)\n",
    "    lisst.append(dictt_react)\n",
    "#     lisst.append(dictt_metho)\n",
    "#     lisst.append(dictt_prod)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a93dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7fb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ab7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(0.80*(len(train)))]                       # 80% train\n",
    "valid_ = train[int(0.80*(len(train))):int(0.90*(len(train)))] #10% valid \n",
    "test_  = train[int(0.90*(len(train))):]                       #10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d477a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_), len(test_), len(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/data/reat_train.json\", 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a025620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/data/reat_test.json\", 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/data/reat_valid.json\", 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/reactant/data/reat_full.json\", 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebbead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3abb1fe6",
   "metadata": {},
   "source": [
    "**3. QnA for method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49afc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4bd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['Method']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f0319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8213c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f750ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_ind[3004:3100]+indd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_meth = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55067ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dff_meth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057790fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeeee = []\n",
    "for i in range(len(data)):\n",
    "    if int(data.Date[i][-4:]) == 2017:\n",
    "        if len(data.catalyst[i]) != 0:\n",
    "            indeeee.append(i)\n",
    "            \n",
    "len(indeeee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[indeeee].reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82366234",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(len(data)):\n",
    "    if len(data['Method'][i]) != 0:\n",
    "        #print(data['catalyst'][i])\n",
    "        for catt in data['Method'][i]:\n",
    "            y.append(catt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# matplotlib library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ''.join([str(i) for i in y])\n",
    "\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=3,\n",
    "                      max_font_size = 40)\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()\n",
    "\n",
    "plt.imshow(wordcloud) # image show\n",
    "plt.axis('off') # to off the axis of x and y\n",
    "plt.savefig('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/method_2017.pdf',dpi=2000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from matplotlib import rc\n",
    "\n",
    "#Utilize the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Import the warning library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function for get the name of chemical entities and their frequency\n",
    "def get_chemical_entry_count(column, size):\n",
    "    catal = []\n",
    "    #Remove the all punctution\n",
    "    catalyst_column= pd.Series(column).str.replace('[^\\w\\s]','')\n",
    "    for i in range(size):\n",
    "        cat_list = catalyst_column[i].split(\" \")\n",
    "        for j in range(len(cat_list)):\n",
    "            #Appending the catalyst\n",
    "            catal.append(cat_list[j])\n",
    "            #frequency of existence\n",
    "            unique, frequency = np.unique(np.array(catal), return_counts = True)\n",
    "            #Making data frame of uniqueness and frequency\n",
    "            df_unique_counts = pd.DataFrame({'section name' : unique, 'frequency' : frequency})\n",
    "            \n",
    "    return df_unique_counts\n",
    "\n",
    "#Call the defined function\n",
    "df_cat_freq = get_chemical_entry_count(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the data frame based on frequency available\n",
    "sort = df_cat_freq.sort_values(\"frequency\", axis = 0, ascending = False).reset_index(drop = True)\n",
    "#print(Number of unique chemicals)\n",
    "print('Number of unique chemicals:', sort.shape[0])\n",
    "#Shows the first 5 rows\n",
    "sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2020\n",
    "df_list_catalyst = sort\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95002bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2021\n",
    "df_list_catalyst1 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022\n",
    "df_list_catalyst2 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafee143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023\n",
    "df_list_catalyst3 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n",
    "\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts1 = df_list_catalyst1.frequency\n",
    "tokens1 = df_list_catalyst1['section name']\n",
    "\n",
    "ranks1 = np.arange(1, len(counts1)+1)\n",
    "indices1 = argsort(-counts1)\n",
    "frequencies1 = counts1[indices1]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts2 = df_list_catalyst2.frequency\n",
    "tokens2 = df_list_catalyst2['section name']\n",
    "\n",
    "ranks2 = np.arange(1, len(counts2)+1)\n",
    "indices2 = argsort(-counts2)\n",
    "frequencies2 = counts2[indices2]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts3 = df_list_catalyst3.frequency\n",
    "tokens3 = df_list_catalyst3['section name']\n",
    "\n",
    "ranks3 = np.arange(1, len(counts3)+1)\n",
    "indices3 = argsort(-counts3)\n",
    "frequencies3 = counts3[indices3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff435498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,10**3)\n",
    "plt.xlim(1,0.1*10**4)\n",
    "\n",
    "loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2020')\n",
    "\n",
    "\n",
    "\n",
    "xlabel(\"Rank of method entity\",fontweight='bold', fontsize=16)\n",
    "ylabel(\"Absolute frequency of method entity\",fontweight='bold', fontsize=16)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "# for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "#     dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "#                  verticalalignment=\"bottom\",\n",
    "#                  horizontalalignment=\"left\", fontweight='bold',\n",
    "#                  fontsize=12)\n",
    "    \n",
    "# for n in list(logspace(-0.5, log10(len(counts1)-2), 25).astype(int)):\n",
    "#     dummy1 = text(ranks1[n], frequencies1[n], \" \" + tokens1[indices1[n]], \n",
    "#                  verticalalignment=\"bottom\",\n",
    "#                  horizontalalignment=\"left\", fontweight='bold',\n",
    "#                  fontsize=12)\n",
    "    \n",
    "# for n in list(logspace(-0.5, log10(len(counts2)-2), 25).astype(int)):\n",
    "#     dummy2 = text(ranks2[n], frequencies2[n], \" \" + tokens2[indices2[n]], \n",
    "#                  verticalalignment=\"bottom\",\n",
    "#                  horizontalalignment=\"left\", fontweight='bold',\n",
    "#                  fontsize=12)\n",
    "    \n",
    "# for n in list(logspace(-0.5, log10(len(counts3)-2), 25).astype(int)):\n",
    "#     dummy3 = text(ranks3[n], frequencies3[n], \" \" + tokens3[indices3[n]], \n",
    "#                  verticalalignment=\"bottom\",\n",
    "#                  horizontalalignment=\"left\", fontweight='bold',\n",
    "#                  fontsize=12)\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/zipf_method.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae63617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,0.5*10**3)\n",
    "plt.xlim(0.9,0.9*10**2)\n",
    "\n",
    "# loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "# loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "# loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2017')\n",
    "\n",
    "\n",
    "xlabel(\"Rank of method entity\",fontweight='bold', fontsize=21)\n",
    "ylabel(\"Absolute frequency of method entity\",fontweight='bold', fontsize=21)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=18, rotation= 'vertical')\n",
    "    \n",
    "\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/zipf_method_text_2017.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac075529",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_meth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff_meth['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat = {}   #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho= {} #Dict for method question\n",
    "    dictt_prod = {} #Dict for product question\n",
    "    \n",
    "    ##Data making for methods \n",
    "    metho =  dff_meth['Method'][inde]\n",
    "    if len(metho) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_metho[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_metho[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the methods used?\"]   #Question write here\n",
    "        dictt_metho[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_metho = answers(inde, abst,metho)\n",
    "        j = j+1\n",
    "    elif len(metho) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_metho[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_metho[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the methods used?\"] \n",
    "        dictt_metho[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_metho =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "        \n",
    "    \n",
    "    \n",
    "#     dictt_cat[\"answers\"] = listttt_cat\n",
    "#     dictt_react[\"answers\"] = listttt_react\n",
    "    dictt_metho[\"answers\"] = listttt_metho\n",
    "#     dictt_prod[\"answers\"]  = listttt_prod\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "#     lisst.append(dictt_cat)\n",
    "#     lisst.append(dictt_react)\n",
    "    lisst.append(dictt_metho)\n",
    "#     lisst.append(dictt_prod)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00348a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6033a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92aa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(0.80*(len(train)))]                       # 80% train\n",
    "valid_ = train[int(0.80*(len(train))):int(0.90*(len(train)))] #10% valid \n",
    "test_  = train[int(0.90*(len(train))):]                       #10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_), len(test_), len(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/data/meth_train.json\", 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/data/meth_test.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/data/meth_valid.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/methods/data/meth_full.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3797e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484d5130",
   "metadata": {},
   "source": [
    "**4. QnA for product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d078696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['Product']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89916c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06708e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_ind[3004:3100]+indd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee77e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_prod = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea478db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dff_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeeee = []\n",
    "for i in range(len(data)):\n",
    "    if int(data.Date[i][-4:]) == 2017:\n",
    "        if len(data.Product[i]) != 0:\n",
    "            indeeee.append(i)\n",
    "            \n",
    "len(indeeee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50198e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[indeeee].reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(len(data)):\n",
    "    if len(data['Product'][i]) != 0:\n",
    "        #print(data['catalyst'][i])\n",
    "        for catt in data['Product'][i]:\n",
    "            y.append(catt)\n",
    "print(len(y))            \n",
    "y_new = []\n",
    "\n",
    "for nn in y:\n",
    "    if ('waste' not in nn) and ('poly' not in nn ) and  ('The' not in nn ):\n",
    "        y_new.append(nn)\n",
    "len(y_new)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# matplotlib library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ''.join([str(i) for i in y_new])\n",
    "\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=3,\n",
    "                      max_font_size = 40)\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()\n",
    "\n",
    "plt.imshow(wordcloud) # image show\n",
    "plt.axis('off') # to off the axis of x and y\n",
    "plt.savefig('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/product_2017.pdf',dpi=2000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from matplotlib import rc\n",
    "\n",
    "#Utilize the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Import the warning library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function for get the name of chemical entities and their frequency\n",
    "def get_chemical_entry_count(column, size):\n",
    "    catal = []\n",
    "    #Remove the all punctution\n",
    "    catalyst_column= pd.Series(column).str.replace('[^\\w\\s]','')\n",
    "    for i in range(size):\n",
    "        cat_list = catalyst_column[i].split(\" \")\n",
    "        for j in range(len(cat_list)):\n",
    "            #Appending the catalyst\n",
    "            catal.append(cat_list[j])\n",
    "            #frequency of existence\n",
    "            unique, frequency = np.unique(np.array(catal), return_counts = True)\n",
    "            #Making data frame of uniqueness and frequency\n",
    "            df_unique_counts = pd.DataFrame({'section name' : unique, 'frequency' : frequency})\n",
    "            \n",
    "    return df_unique_counts\n",
    "\n",
    "#Call the defined function\n",
    "df_cat_freq = get_chemical_entry_count(y_new, len(y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdebe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the data frame based on frequency available\n",
    "sort = df_cat_freq.sort_values(\"frequency\", axis = 0, ascending = False).reset_index(drop = True)\n",
    "#print(Number of unique chemicals)\n",
    "print('Number of unique chemicals:', sort.shape[0])\n",
    "#Shows the first 5 rows\n",
    "sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2020\n",
    "df_list_catalyst = sort\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.frequency\n",
    "tokens = df_list_catalyst['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year 2021\n",
    "df_list_catalyst1 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b66a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022\n",
    "df_list_catalyst2 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f15f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023\n",
    "df_list_catalyst3 = sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20849c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_list_catalyst3 = df_list_catalyst3.drop_duplicates(subset='frequency', keep='first').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A zipf line plot is shown\n",
    "counts = df_list_catalyst.head(20).frequency\n",
    "tokens = df_list_catalyst.head(20)['section name']\n",
    "\n",
    "ranks = np.arange(1, len(counts)+1)\n",
    "indices = argsort(-counts)\n",
    "frequencies = counts[indices]\n",
    "\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts1 = df_list_catalyst1.head(20).frequency\n",
    "tokens1 = df_list_catalyst1.head(20)['section name']\n",
    "\n",
    "ranks1 = np.arange(1, len(counts1)+1)\n",
    "indices1 = argsort(-counts1)\n",
    "frequencies1 = counts1[indices1]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts2 = df_list_catalyst2.head(20).frequency\n",
    "tokens2 = df_list_catalyst2.head(20)['section name']\n",
    "\n",
    "ranks2 = np.arange(1, len(counts2)+1)\n",
    "indices2 = argsort(-counts2)\n",
    "frequencies2 = counts2[indices2]\n",
    "\n",
    "#A zipf line plot is shown\n",
    "counts3 = df_list_catalyst3.frequency\n",
    "tokens3 = df_list_catalyst3['section name']\n",
    "\n",
    "ranks3 = np.arange(1, len(counts3)+1)\n",
    "indices3 = argsort(-counts3)\n",
    "frequencies3 = counts3[indices3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5bcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(min(frequencies),0.5*10**3)\n",
    "plt.xlim(1,10**2)\n",
    "\n",
    "loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2020')\n",
    "\n",
    "\n",
    "\n",
    "xlabel(\"Rank of product entity\",fontweight='bold', fontsize=16)\n",
    "ylabel(\"Absolute frequency of product entity\",fontweight='bold', fontsize=16)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts1)-2), 25).astype(int)):\n",
    "    dummy1 = text(ranks1[n], frequencies1[n], \" \" + tokens1[indices1[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts2)-2), 25).astype(int)):\n",
    "    dummy2 = text(ranks2[n], frequencies2[n], \" \" + tokens2[indices2[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "    \n",
    "for n in list(logspace(-0.5, log10(len(counts3)-2), 25).astype(int)):\n",
    "    dummy3 = text(ranks3[n], frequencies3[n], \" \" + tokens3[indices3[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=12)\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "#plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/zipf_product_text.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca102556",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.ylim(1,0.4*10**4)\n",
    "plt.xlim(0.9,1.20*10**3)\n",
    "\n",
    "# loglog(ranks3, frequencies3, marker=\".\", label = '2023')\n",
    "# loglog(ranks2, frequencies2, marker=\".\", label = '2022')\n",
    "# loglog(ranks1, frequencies1, marker=\".\", label = '2021')\n",
    "loglog(ranks, frequencies, marker=\".\", label = '2017')\n",
    "\n",
    "\n",
    "xlabel(\"Rank of product entity\",fontweight='bold', fontsize=21)\n",
    "ylabel(\"Absolute frequency of product entity\",fontweight='bold', fontsize=21)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "grid(True)\n",
    "for n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n",
    "    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n",
    "                 verticalalignment=\"bottom\",\n",
    "                 horizontalalignment=\"left\", fontweight='bold',\n",
    "                 fontsize=18,rotation='vertical')\n",
    "    \n",
    "\n",
    "#Save the plot\n",
    "plt.legend()\n",
    "plt.savefig(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/zipf_product_text_2017.pdf', dpi=5000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a0f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff_prod['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat =   {}   #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho=  {} #Dict for method question\n",
    "    dictt_prod =  {} #Dict for product question\n",
    "    \n",
    "    #The data making for the product entries\n",
    "    prod =  dff_prod['Product'][inde]\n",
    "    if len(prod) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_prod[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_prod[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the products formed?\"]   #Question write here\n",
    "        dictt_prod[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_prod = answers(inde, abst,prod)\n",
    "        j = j+1\n",
    "        \n",
    "    elif len(prod) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_prod[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_prod[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the products formed?\"] \n",
    "        dictt_prod[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_prod =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "        \n",
    "    \n",
    "    \n",
    "#     dictt_cat[\"answers\"] = listttt_cat\n",
    "#     dictt_react[\"answers\"] = listttt_react\n",
    "#     dictt_metho[\"answers\"] = listttt_metho\n",
    "    dictt_prod[\"answers\"]  = listttt_prod\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "#     lisst.append(dictt_cat)\n",
    "#     lisst.append(dictt_react)\n",
    "#     lisst.append(dictt_metho)\n",
    "    lisst.append(dictt_prod)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4155dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e05970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4fec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(0.80*(len(train)))]                       # 80% train\n",
    "valid_ = train[int(0.80*(len(train))):int(0.90*(len(train)))] #10% valid \n",
    "test_  = train[int(0.90*(len(train))):]                       #10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf270c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_), len(test_), len(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/data/prod_train.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342424fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/data/prod_test.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/data/prod_valid.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5171c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/product/data/prod_full.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb04668",
   "metadata": {},
   "source": [
    "**5. Question and answer process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0214934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff=df_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff[\"process\"]):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc598ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inde = []\n",
    "for ii in range(len(dff)):\n",
    "    inde.append(ii)\n",
    "\n",
    "ext_ind = []\n",
    "for iii in inde:\n",
    "    if iii not in indd:\n",
    "        ext_ind.append(iii)\n",
    "        \n",
    "\n",
    "len(ext_ind), len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93582b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dee7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_ind[3004:3100]+indd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f28d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_proc = dff.loc[indd].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_proc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff_proc['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat = {}   #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho= {} #Dict for method question\n",
    "    dictt_prod = {} #Dict for product question\n",
    "    dictt_proc = {} #Dict for process question\n",
    "    \n",
    "    #The data making for the catalyst entries\n",
    "    comp =  dff_proc['process'][inde]\n",
    "    if len(comp) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_proc[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_proc[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the process parameters values?\"]   #Question write here\n",
    "        dictt_proc[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_proc = answers(inde, abst,comp)\n",
    "        j = j+1\n",
    "    elif len(comp) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_proc[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_proc[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the process parameters values?\"]\n",
    "        dictt_proc[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_proc =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "    \n",
    "    \n",
    "#     dictt_cat[\"answers\"] = listttt_cat\n",
    "#     dictt_react[\"answers\"] = listttt_react\n",
    "#     dictt_metho[\"answers\"] = listttt_metho\n",
    "#     dictt_prod[\"answers\"]  = listttt_prod\n",
    "    dictt_proc['answers'] = listttt_proc\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "#     lisst.append(dictt_cat)\n",
    "#     lisst.append(dictt_react)\n",
    "#     lisst.append(dictt_metho)\n",
    "#     lisst.append(dictt_prod)\n",
    "    lisst.append(dictt_proc)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(0.80*(len(train)))]                       # 80% train\n",
    "valid_ = train[int(0.80*(len(train))):int(0.90*(len(train)))] #10% valid \n",
    "test_  = train[int(0.90*(len(train))):]                       #10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_), len(test_), len(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/process/data/pro_train.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ff9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/process/data/pro_test.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f71441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/process/data/pro_valid.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01af8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/process/data/pro_full.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_parquet(\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/result/data_full.gzip\" ,compression='gzip')\n",
    "# df.to_parquet(FILE_PATH + '{}.gzip'.format(csv_file),compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea23c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_answer_cat = []\n",
    "for a in dff_cat.index:\n",
    "    len_answer_cat.append(len(dff_cat[\"catalyst\"][a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcd51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_answer_meth = []\n",
    "for a in dff_meth.index:\n",
    "    len_answer_meth.append(len(dff_meth[\"Method\"][a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_answer_react = []\n",
    "for a in dff_react.index:\n",
    "    len_answer_react.append(len(dff_react[\"reactant\"][a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_answer_prod = []\n",
    "for a in dff_prod.index:\n",
    "    len_answer_prod.append(len(dff_prod[\"Product\"][a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_answer_pro = []\n",
    "for a in dff_proc.index:\n",
    "    len_answer_pro.append(len(dff_proc[\"process\"][a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean and std of lists:\", np.mean(len_answer_cat), np.std(len_answer_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eeeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean and std of lists:\", np.mean(len_answer_meth), np.std(len_answer_meth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean and std of lists:\", np.mean(len_answer_pro), np.std(len_answer_pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean and std of lists:\", np.mean(len_answer_prod), np.std(len_answer_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdedda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean and std of lists:\", np.mean(len_answer_react), np.std(len_answer_react))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5d60c",
   "metadata": {},
   "source": [
    "**QnA data making**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85146398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b37a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indee = []\n",
    "for d in df.index:\n",
    "    if (len(df['process'][d]) != 0) and (len(df['catalyst'][d]) != 0) and (len(df['reactant'][d]) != 0) and (len(df['Method'][d]) != 0) and (len(dff['Product'][d]) != 0):\n",
    "        indee.append(d)\n",
    "        \n",
    "len(indee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "indd = []\n",
    "for i,cata in enumerate(dff['catalyst']):\n",
    "    if len(cata) != 0:\n",
    "        indd.append(i)\n",
    "        \n",
    "len(indd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfed2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b92c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "inde = []\n",
    "for ii in range(len(dff)):\n",
    "    inde.append(ii)\n",
    "\n",
    "ext_ind = []\n",
    "for iii in inde:\n",
    "    if iii not in indd:\n",
    "        ext_ind.append(iii)\n",
    "        \n",
    "\n",
    "len(ext_ind), len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.loc[indd].reset_index(drop = True)\n",
    "len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"process\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29274e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['process'] = dff['process'].apply(deleteduplicate)\n",
    "dff['Product'] = dff['Product'].apply(deleteduplicate)\n",
    "dff['reactant'] = dff['reactant'].apply(deleteduplicate)\n",
    "dff[\"Method\"] = dff['Method'].apply(deleteduplicate)\n",
    "dff['catalyst'] = dff['catalyst'].apply(deleteduplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat   = {} #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho = {} #Dict for method question\n",
    "    dictt_prod  = {} #Dict for product question\n",
    "    dictt_proc  = {} #Dict for process question\n",
    "    \n",
    "    #The data making for the catalyst entries\n",
    "    comp =  dff['catalyst'][inde]\n",
    "    if len(comp) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_cat[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_cat[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the materials used as catalyst?\"]   #Question write here\n",
    "        dictt_cat[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_cat = answers(inde, abst,comp)\n",
    "        j = j+1\n",
    "    elif len(comp) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_cat[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_cat[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the materials used as catalyst?\"] \n",
    "        dictt_cat[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_cat =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "    \n",
    "    #Data making for reactant(polymers) \n",
    "    react = dff['reactant'][inde] \n",
    "    if len(react) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_react[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_react[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the reactants used?\"]   #Question write here\n",
    "        dictt_react[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_react = answers(inde, abst,react)\n",
    "        j = j+1\n",
    "    elif len(react) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_react[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_react[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the reactants used?\"] \n",
    "        dictt_react[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_react =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "\n",
    "    #Data making for methods \n",
    "    metho = dff['Method'][inde] \n",
    "    if len(metho) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_metho[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_metho[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the methods used?\"]   #Question write here\n",
    "        dictt_metho[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_metho = answers(inde, abst,metho)\n",
    "        j = j+1\n",
    "    elif len(metho) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_metho[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_metho[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the methods used?\"] \n",
    "        dictt_metho[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_metho =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "        \n",
    "    #The data making for the product entries\n",
    "    prod =  dff['Product'][inde]\n",
    "    if len(prod) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_prod[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_prod[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the products formed?\"]   #Question write here\n",
    "        dictt_prod[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_prod = answers(inde, abst,prod)\n",
    "        j = j+1\n",
    "        \n",
    "    elif len(prod) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_prod[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_prod[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the products formed?\"] \n",
    "        dictt_prod[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_prod =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "        \n",
    "        \n",
    "    #The data making for the process entries\n",
    "    proc =  dff['process'][inde]\n",
    "    if len(proc) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_proc[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_proc[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the process parameters values?\"]   #Question write here\n",
    "        dictt_proc[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_proc = answers(inde, abst,proc)\n",
    "        j = j+1\n",
    "        \n",
    "    elif len(proc) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_proc[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_proc[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the process parameters values?\"] \n",
    "        dictt_proc[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_proc =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "    \n",
    "\n",
    "    dictt_cat[\"answers\"] = listttt_cat\n",
    "    dictt_react[\"answers\"] = listttt_react\n",
    "    dictt_metho[\"answers\"] = listttt_metho\n",
    "    dictt_prod[\"answers\"]  = listttt_prod\n",
    "    dictt_proc[\"answers\"]  = listttt_proc\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "    lisst.append(dictt_cat)\n",
    "    lisst.append(dictt_react)\n",
    "    lisst.append(dictt_metho)\n",
    "    lisst.append(dictt_prod)\n",
    "    lisst.append(dictt_proc)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81677a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb517d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train[:int(0.70*(len(train)))]                       #70% train\n",
    "valid_ = train[int(0.70*(len(train))):int(0.85*(len(train)))] #15% valid \n",
    "test_  = train[int(0.85*(len(train))):]                       #15% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_), len(test_), len(valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_individual/with_dupli/bert/full_train_2.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_individual/with_dupli/bert/full_test_2.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a704c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_individual/with_dupli/bert/full_valid_2.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ad2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_individual/with_dupli/full_train_full_2.json', 'w') as F:\n",
    "    # Use the json dumps method to write the list to disk\n",
    "    F.write(json.dumps(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93526886",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(r\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_with_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_individual/with_dupli/data.txt', header=None, index=None, sep=' ', mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47953db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfe8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89dba40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d3592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2f49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e90a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(r\"/home/user3/Documents/avan_phd/Objective_3/Objective_3_QnA/data/data qna/data_with_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3f0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b33cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(num, total_text, catalystss):\n",
    "    listss =  []  #Above list for answer  \n",
    "\n",
    "    for a in range(len(catalystss)):\n",
    "    #if len(catalystss) != 0:\n",
    "        dicttt = {} # One anwser list\n",
    "        dicttt[\"text\"] = catalystss[a]\n",
    "        values = total_text.split(catalystss[a])\n",
    "        b = 0\n",
    "        for c in values[0]:\n",
    "            b = b + 1\n",
    "        dicttt[\"answer_start\"] = b\n",
    "\n",
    "        listss.append(dicttt)\n",
    "        \n",
    "    return listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_react = dff_react['Abstract']\n",
    "len(ddf_react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "j =1\n",
    "for inde,abst in enumerate(dff_prod['Abstract']):\n",
    "    data1 = {} #This list for a context \n",
    "    \n",
    "    data1[\"context\"] =  abst\n",
    "    \n",
    "    dictt_cat = {}   #Dict for catalyst question\n",
    "    dictt_react = {} #Dict for reactants question\n",
    "    dictt_metho= {} #Dict for method question\n",
    "    dictt_prod = {} #Dict for product question\n",
    "    \n",
    "#     The data making for the catalyst entries\n",
    "#     comp =  dff_cat['catalyst'][inde]\n",
    "#     if len(comp) != 0:\n",
    "#         listt = []\n",
    "#         #This dict for QnA task\n",
    "#         dictt_cat[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "#         boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "#         dictt_cat[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "#         ques = [\"What is the name of catalyst?\"]   #Question write here\n",
    "#         dictt_cat[\"question\"] = ques[0]\n",
    "\n",
    "#         listttt_cat = answers(inde, abst,comp)\n",
    "#         j = j+1\n",
    "#     elif len(comp) == 0:\n",
    "#         #THis dict for QnA task\n",
    "#         dictt_cat[\"id\"] = str(j)\n",
    "\n",
    "#         boolen_list = [True, False]\n",
    "#         dictt_cat[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "#         ques = [\"What is the name of catalyst?\"] \n",
    "#         dictt_cat[\"question\"] = ques[0]\n",
    "\n",
    "#         listttt_cat =  []\n",
    "#         #listss.append(answers(sent, s))\n",
    "#         j = j+1\n",
    "    \n",
    "    #data1 = {} #This list for a context \n",
    "    \n",
    "#     data1[\"context\"] =  abst\n",
    "    \n",
    "    #Data making for reactant(polymers) \n",
    "#     react = dff_react['reactant'][inde] \n",
    "#     if len(react) != 0:\n",
    "#         listttt = []\n",
    "#         #This dict for QnA task\n",
    "#         dictt_react[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "#         boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "#         dictt_react[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "#         ques = [\"What is the name of reactant?\"]   #Question write here\n",
    "#         dictt_react[\"question\"] = ques[0]\n",
    "\n",
    "#         listttt_react = answers(inde, abst,react)\n",
    "#         j = j+1\n",
    "#     elif len(react) == 0:\n",
    "#         #THis dict for QnA task\n",
    "#         dictt_react[\"id\"] = str(j)\n",
    "\n",
    "#         boolen_list = [True, False]\n",
    "#         dictt_react[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "#         ques = [\"What is the name of reactant?\"] \n",
    "#         dictt_react[\"question\"] = ques[0]\n",
    "\n",
    "#         listttt_react =  []\n",
    "#         #listss.append(answers(sent, s))\n",
    "#         j = j+1\n",
    "\n",
    "#     #Data making for methods \n",
    "#     metho = dff_meth['Method'][inde] \n",
    "#     if len(metho) != 0:\n",
    "#         listt = []\n",
    "#         #This dict for QnA task\n",
    "#         dictt_metho[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "#         boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "#         dictt_metho[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "#         ques = [\"What is the name of method?\"]   #Question write here\n",
    "#         dictt_metho[\"question\"] = ques[0]\n",
    "\n",
    "#         listttt_metho = answers(inde, abst,metho)\n",
    "#         j = j+1\n",
    "#     elif len(metho) == 0:\n",
    "#         #THis dict for QnA task\n",
    "#         dictt_metho[\"id\"] = str(j)\n",
    "\n",
    "#         boolen_list = [True, False]\n",
    "#         dictt_metho[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "#         ques = [\"What is the name of method?\"] \n",
    "#         dictt_metho[\"question\"] = ques[0]\n",
    "\n",
    "#         listttt_metho =  []\n",
    "#         #listss.append(answers(sent, s))\n",
    "#         j = j+1\n",
    "        \n",
    "#     #The data making for the product entries\n",
    "    prod =  dff_prod['Product'][inde]\n",
    "    if len(prod) != 0:\n",
    "        listt = []\n",
    "        #This dict for QnA task\n",
    "        dictt_prod[\"id\"] = str(j)   # j tells the question number\n",
    "\n",
    "        boolen_list = [True, False]    # tells the is it possible to answer or not\n",
    "        dictt_prod[\"is_impossible\"] =  boolen_list[1]\n",
    "\n",
    "        ques = [\"What are the name of products?\"]   #Question write here\n",
    "        dictt_prod[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_prod = answers(inde, abst,prod)\n",
    "        j = j+1\n",
    "        \n",
    "    elif len(prod) == 0:\n",
    "        #THis dict for QnA task\n",
    "        dictt_prod[\"id\"] = str(j)\n",
    "\n",
    "        boolen_list = [True, False]\n",
    "        dictt_prod[\"is_impossible\"] =  boolen_list[0]\n",
    "\n",
    "        ques = [\"What are the name of products?\"] \n",
    "        dictt_prod[\"question\"] = ques[0]\n",
    "\n",
    "        listttt_prod =  []\n",
    "        #listss.append(answers(sent, s))\n",
    "        j = j+1\n",
    "    \n",
    "\n",
    "#     dictt_cat[\"answers\"] = listttt_cat\n",
    "#     dictt_react[\"answers\"] = listttt_react\n",
    "#     dictt_metho[\"answers\"] = listttt_metho\n",
    "    dictt_prod[\"answers\"]  = listttt_prod\n",
    "    \n",
    "    lisst= []    #QnA list where question and answer exist\n",
    "    \n",
    "#     lisst.append(dictt_cat)\n",
    "#     lisst.append(dictt_react)\n",
    "#     lisst.append(dictt_metho)\n",
    "    lisst.append(dictt_prod)\n",
    "    \n",
    "    data1[\"qas\"] = lisst\n",
    "    \n",
    "    train.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e83ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =  nlp(sent_tokenize(df_pe['Abstract'][2019])[5])\n",
    "\n",
    "for a, chunk in enumerate(doc.noun_chunks):\n",
    "    #print(chunk.text)\n",
    "    if 'yield' in chunk.text: \n",
    "        print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "productextract(df_pe['Abstract'][2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen in sent_tokenize(df_pe['Abstract'][2021]):\n",
    "    print(sen,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0879843",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactantextract(df_pe['Abstract'][2017]), methodextract(df_pe['Abstract'][2017]), productextract(df_pe['Abstract'][2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dfa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"polyethylene\",\"waste\",\"plastic\", 'PET', 'wastes' ]   #We will try this words\n",
    "\n",
    "def reactantextract(text):\n",
    "    reactants =  ['poly', 'waste', \"wastes\", \"plastic\", \"plastics\"]\n",
    "    reactant = []\n",
    "    for sen in sent_tokenize(text):\n",
    "#         if \"poly\" in sen:\n",
    "        doc = nlp(sen)\n",
    "        for a, chunk in enumerate(doc.noun_chunks):\n",
    "            #print(chunk)\n",
    "            for react in reactants:\n",
    "                if react in chunk.text:\n",
    "                    reactant.append(chunk.text)\n",
    "    return reactant\n",
    "\n",
    "reactantextract(df_pe['Abstract'][2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen in sent_tokenize(df['Abstract'][0]):\n",
    "    if \"pyrolysis\" in sen:\n",
    "        doc = nlp(sen)\n",
    "        print(sen, \"\\n\")\n",
    "        for text in doc:\n",
    "            print(text,\">>>>>>>>>\" ,text.pos_, \">>>>>>>>\", text.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sent_tokenize(df.Abstract[30])[0])\n",
    "for text in doc:\n",
    "    print(text,\">>>>>>>>>\" ,text.pos_, \">>>>>>>>\", text.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3de391",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize(df['Abstract'][440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4808b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13503 out of 21000\n",
    "len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inddd =  []\n",
    "for i in dff.index:\n",
    "    if len(dff['Product'][i]) != 0:\n",
    "        inddd.append(i)\n",
    "        \n",
    "dff_prod = dff.loc[inddd].reset_index(drop = True)\n",
    "len(dff_prod)     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_react"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b46390",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bart11",
   "language": "python",
   "name": "bart11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
