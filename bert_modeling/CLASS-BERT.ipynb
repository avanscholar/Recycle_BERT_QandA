{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ff993",
   "metadata": {
    "id": "123ff993"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ace81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.  version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edef0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('is there cuda available:',torch.cuda.is_available())\n",
    "print('working of gpu',torch.cuda.current_device())\n",
    "print('Name of gpu original or scientific',torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to change the gpu\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71229c",
   "metadata": {
    "id": "ca71229c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159d77b",
   "metadata": {
    "id": "7159d77b"
   },
   "outputs": [],
   "source": [
    "#Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf24c3",
   "metadata": {
    "id": "9ecf24c3"
   },
   "outputs": [],
   "source": [
    "# If you want to install the packages\n",
    "# install pytorch-pretrained-bert from PyPI\n",
    "#!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e106169",
   "metadata": {
    "id": "2e106169"
   },
   "outputs": [],
   "source": [
    "#All important libraries to run \n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics as stats\n",
    "\n",
    "#Cloned the bert_sklearn API here\n",
    "!git clone -b master https://github.com/charles9n/bert-sklearn\n",
    "!cd bert-sklearn; pip install .\n",
    "\n",
    "#Import the pretrained model \n",
    "sys.path.append(\"../\") \n",
    "from bert_sklearn import BertTokenClassifier, BertClassifier, BertRegressor\n",
    "#It is use to load the trained model\n",
    "from bert_sklearn import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd153a5",
   "metadata": {
    "id": "afd153a5"
   },
   "outputs": [],
   "source": [
    "#data load of pet\n",
    "df_pet = pd.read_csv(path + '2_abstract_pet_recycle_methods.csv')\n",
    "df_pet =  df_pet.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pet.shape)\n",
    "df_pet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UCa8tDT14QaT",
   "metadata": {
    "id": "UCa8tDT14QaT"
   },
   "outputs": [],
   "source": [
    "#data load of ps\n",
    "df_ps = pd.read_csv(path + '0_abstract_ps_recycle_methods.csv')\n",
    "df_ps =  df_ps.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_ps.shape)\n",
    "df_ps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maWGh0-C4QdD",
   "metadata": {
    "id": "maWGh0-C4QdD"
   },
   "outputs": [],
   "source": [
    "# #data load of pe\n",
    "df_pe = pd.read_csv(path + '2_abstract_pe_recycle_methods.csv')\n",
    "df_pe =  df_pe.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pe.shape)\n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NjbdOaFj4Qf4",
   "metadata": {
    "id": "NjbdOaFj4Qf4"
   },
   "outputs": [],
   "source": [
    "#data load of pp\n",
    "df_pp = pd.read_csv(path + '2_abstract_pp_recycle_methods.csv')\n",
    "df_pp =  df_pp.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_pp.shape)\n",
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TJyk5-sC4Qiz",
   "metadata": {
    "id": "TJyk5-sC4Qiz"
   },
   "outputs": [],
   "source": [
    "# concatenating df1 and df2 along rows\n",
    "df_net = pd.concat([df_pe, df_pet,df_pp, df_ps], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48hrs8WobSoO",
   "metadata": {
    "id": "48hrs8WobSoO"
   },
   "outputs": [],
   "source": [
    "df_rel = pd.read_csv(path + 'elsevier_data.csv')\n",
    "df_rel =  df_rel.drop(['Unnamed: 0',\"DOI\",'Title'], axis=1)\n",
    "print('Shape of data frame:', df_rel.shape, df_rel.columns)\n",
    "df_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m_WWmU20bmvU",
   "metadata": {
    "id": "m_WWmU20bmvU"
   },
   "outputs": [],
   "source": [
    "#Relevant abstracts labelling\n",
    "df_net['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8IPWUuSu4Qlk",
   "metadata": {
    "id": "8IPWUuSu4Qlk"
   },
   "outputs": [],
   "source": [
    "#Delete the all entries with nan in abstract column\n",
    "NO_INDEX = []\n",
    "for i in range(len(df_net)):\n",
    "    if type(df_net.Abstract[i]) != float: \n",
    "        NO_INDEX.append(i)\n",
    "#Select some entries        \n",
    "df_net = df_net.iloc[NO_INDEX].reset_index(drop = True)\n",
    "print('Shape of data frame before:', df_net.shape)\n",
    "\n",
    "#Delete the all entries with integer in abstract column\n",
    "NO_INDEXX = []\n",
    "for i in range(len(df_net)):\n",
    "    if df_net.Abstract[i] != '0': \n",
    "        NO_INDEXX.append(i)\n",
    "#Select some entries        \n",
    "df_net = df_net.iloc[NO_INDEXX].reset_index(drop = True)\n",
    "print('Shape of data frame after:', df_net.shape)\n",
    "\n",
    "df_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gXUZ1QVR40bo",
   "metadata": {
    "id": "gXUZ1QVR40bo"
   },
   "outputs": [],
   "source": [
    "# data load of pp\n",
    "df_h2 = pd.read_csv(path + 'elsevier_abstract.csv')\n",
    "df_h2 =  df_h2.drop(['Unnamed: 0'], axis=1)\n",
    "print('Shape of data frame:', df_h2.shape)\n",
    "df_h2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X62_h2qe40ej",
   "metadata": {
    "id": "X62_h2qe40ej"
   },
   "outputs": [],
   "source": [
    "#data load of pp\n",
    "df_m2 = pd.read_csv(path + 'methanol_synthesis.csv')\n",
    "df_m2 =  df_m2.drop(['Unnamed: 0',\"DOI\",'Title'], axis=1)\n",
    "print('Shape of data frame:', df_m2.shape)\n",
    "df_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DKeF36Zt40iK",
   "metadata": {
    "id": "DKeF36Zt40iK"
   },
   "outputs": [],
   "source": [
    "# # concatenating df1 and df2 along rows\n",
    "df_net_1 = pd.concat([df_h2,df_m2], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EnHZtFgC4QpN",
   "metadata": {
    "id": "EnHZtFgC4QpN"
   },
   "outputs": [],
   "source": [
    "#Relevant abstracts labelling\n",
    "df_net_1['label'] = 1  #Not relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eRFc-2K6L6",
   "metadata": {
    "id": "03eRFc-2K6L6"
   },
   "outputs": [],
   "source": [
    "# concatenating df1 and df2 along rows\n",
    "df_net_total = pd.concat([df_net_1, df_net], axis=0).reset_index(drop = True)\n",
    "print('Net shape of data frame:', df_net_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uUiekiLnK6Pf",
   "metadata": {
    "id": "uUiekiLnK6Pf"
   },
   "outputs": [],
   "source": [
    "#Delete the all entries with nan in abstract column\n",
    "NO_INDEX = []\n",
    "for i in range(len(df_net_total)):\n",
    "    if type(df_net_total.Abstract[i]) != float: \n",
    "        NO_INDEX.append(i)\n",
    "#Select some entries        \n",
    "df_net_total = df_net_total.iloc[NO_INDEX].reset_index(drop = True)\n",
    "print('Shape of data frame before:', df_net_total.shape)\n",
    "\n",
    "#Delete the all entries with integer in abstract column\n",
    "NO_INDEXX = []\n",
    "for i in range(len(df_net_total)):\n",
    "    if df_net_total.Abstract[i] != '0': \n",
    "        NO_INDEXX.append(i)\n",
    "#Select some entries        \n",
    "df_net_total = df_net_total.iloc[NO_INDEXX].reset_index(drop = True)\n",
    "print('Shape of data frame after:', df_net_total.shape)\n",
    "\n",
    "df_net_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fn4R1-4WLC-p",
   "metadata": {
    "id": "fn4R1-4WLC-p"
   },
   "outputs": [],
   "source": [
    "#Abstract cleaning\n",
    "def deletespace(text):\n",
    "    text0 = text.replace(\"<jats:p>\",\"\" )\n",
    "    text1 =  text0.replace(\"</jats:p>\", '')\n",
    "    text2 = text1.replace('<jats:title>Abstract</jats:title>\\n', '')\n",
    "    text3 = text2.replace('<p>', \"\")\n",
    "    text4 = text3.replace('</p>', \"\")\n",
    "    text5 = text4.replace('\\n', \"\")\n",
    "    \n",
    "    return text5\n",
    "df_net_total['Abstract'] = df_net_total['Abstract'].apply(deletespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TE4vmJt8LHRF",
   "metadata": {
    "id": "TE4vmJt8LHRF"
   },
   "outputs": [],
   "source": [
    "df =df_net_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6eaf10",
   "metadata": {
    "id": "5a6eaf10"
   },
   "outputs": [],
   "source": [
    "#Remove the punctutions from each sentence \n",
    "sentence = []\n",
    "import re\n",
    "for i in np.arange(0,df.shape[0], 1):\n",
    "    pattern = r'\\[[^()]*\\]'\n",
    "    #s = \"\"\"Issachar is a rawboned[a] (donkey) lying down among the sheep pens.\"\"\"\n",
    "    t = re.sub(pattern, '', df.Abstract[i])\n",
    "    sentence.append(t)\n",
    "df['sentence'] = sentence\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be195a2",
   "metadata": {
    "id": "8be195a2"
   },
   "outputs": [],
   "source": [
    "#The data has input and output\n",
    "X= df.sentence\n",
    "Y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb361f",
   "metadata": {
    "id": "37bb361f"
   },
   "outputs": [],
   "source": [
    "#The data is splited into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3, random_state= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547ca05",
   "metadata": {
    "id": "7547ca05"
   },
   "outputs": [],
   "source": [
    "#Total data points describe\n",
    "print('shape of actual data', df.shape[0])\n",
    "print('shape of train data', X_train.shape[0])\n",
    "print('shape of test data', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e84a5",
   "metadata": {
    "id": "b88e84a5"
   },
   "outputs": [],
   "source": [
    "#Load the pretrained model of BERTclassifier\n",
    "%%time\n",
    "model = BertClassifier(bert_model='bert-base-cased',\n",
    "                            max_seq_length=256,\n",
    "                            epochs=3,\n",
    "                            gradient_accumulation_steps=2,\n",
    "                            learning_rate=3e-6,\n",
    "                            train_batch_size=32,\n",
    "                            eval_batch_size=32,\n",
    "                            validation_fraction=0.30,\n",
    "                       logfile='bert_sklearn_new.log',\n",
    "                      warmup_proportion = 0.2,\n",
    "                      random_state = 42)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cc43f",
   "metadata": {
    "id": "ec5cc43f"
   },
   "outputs": [],
   "source": [
    "# finetune model on train data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aVzrMWsXmBCy",
   "metadata": {
    "id": "aVzrMWsXmBCy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,len(train_loss)+1,1), train_loss, color='red', label= 'Train', linewidth=2.5)\n",
    "plt.plot(range(1,len(val_loss)+1,1), val_loss, color =  'Blue', label = 'Validation', linewidth=2.5)\n",
    "#plt.title('Classification loss')\n",
    "plt.legend(frameon=False,prop={'weight':'bold',\"size\":16})\n",
    "plt.xlabel('Number of epoch',fontweight='bold', fontsize=18)\n",
    "plt.ylabel('Loss',fontweight='bold', fontsize=18)\n",
    "#plt.title('GP Regression',fontweight='bold')\n",
    "#plt.axis('square')\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 3\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=4)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=4)\n",
    "\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(bottom=True, top=False, left=True, right=False)\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "plt.xticks(rotation = '0', fontsize = 14)\n",
    "plt.yticks(rotation = '0', fontsize = 14)\n",
    "#plt.legend(handles=h, labels=np.arange(0.9,0.85), title=\"Quality\")\n",
    "#plt.rcParams.update({'legend.fontweight':'bold'}\n",
    "#plt.savefig('line_plot.pdf')\n",
    "plt.savefig(r'learning_classi.pdf', dpi=5000,bbox_inches =\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b4b5f",
   "metadata": {
    "id": "8f4b4b5f"
   },
   "outputs": [],
   "source": [
    "#Save model to disk\n",
    "savefile = 'classifi_model50_256_with_netrual.bin'\n",
    "model.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test data\n",
    "y_pred_train = model.predict(X_test)\n",
    "\n",
    "# get predictions on train data\n",
    "y_pred_test = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b47d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print report on classifier stats\n",
    "print(classification_report(df_net_total.label, y_pred_train))\n",
    "\n",
    "#Get accuracy on train data\n",
    "print('Accuracy of test:', accuracy_score(df_net_total.label, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print report on classifier stats\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "#Accuracy on train data\n",
    "print('Accuracy of test:', accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I-_2joqoxjo3",
   "metadata": {
    "id": "I-_2joqoxjo3"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Change figure size and increase dpi for better resolution\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "# Scale up the size of all text\n",
    "sns.set(font_scale = 1.1)\n",
    "\n",
    "# Plot Confusion Matrix using Seaborn heatmap()\n",
    "# Parameters:\n",
    "# first param - confusion matrix in array format   \n",
    "# annot = True: show the numbers in each heatmap cell\n",
    "# fmt = 'd': show numbers as integers. \n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, fmt='d',square=True)\n",
    "\n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted Class\", fontsize=22,labelpad=20, fontweight='bold')\n",
    "ax.xaxis.set_ticklabels(['0', '1'], fontsize=20, fontweight='bold')\n",
    "\n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual Class\", fontsize=22, labelpad=20, fontweight='bold')\n",
    "ax.yaxis.set_ticklabels(['0', '1'], fontsize=20, fontweight='bold')\n",
    "\n",
    "# set plot title\n",
    "#ax.set_title(\"Confusion Matrix for the Diabetes Detection Model\", fontsize=14, pad=20)\n",
    "#plt.savefig(\"test_confusion.pdf\",dpi=2000,bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe0169",
   "metadata": {
    "id": "SeGoDZmLyGGT"
   },
   "source": [
    "**End of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501d97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
